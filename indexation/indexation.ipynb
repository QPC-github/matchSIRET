{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18ba968-9f71-4577-9c4a-4bed97071180",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fill index _etablissements_ of elasticsearch\n",
    "elastic path : http://elasticsearch-master:9200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449e748e-2494-43f1-a833-b14adbcddbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install elasticsearch_dsl\n",
    "#!pip install minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5e87a-773d-4086-94dd-e964764f3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mc cp s3/projet-matchsiret/sirene.db data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0c944b-5e23-467b-a1c4-d1ef1ccc0570",
   "metadata": {
    "tags": []
   },
   "source": [
    "### helpers utils \n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/helpers/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f44689b-5048-4932-b457-87369347a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unique_list(lst):\n",
    "    ulist = []\n",
    "    [ulist.append(x) for x in lst if x not in ulist]\n",
    "    return ulist\n",
    "\n",
    "\n",
    "def unique_string(a):\n",
    "    return \" \".join(unique_list(a.strip().split(\",\"))).strip()\n",
    "\n",
    "\n",
    "def get_empty_string_if_none(string):\n",
    "    if string is None:\n",
    "        return \"\"\n",
    "    return string\n",
    "\n",
    "\n",
    "def dict_from_row(row):\n",
    "    return dict(zip(row.keys(), row))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d80c8-12c5-4633-b5cd-c8242289f3b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### data enrichment\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/data_enrichment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af3ee6a-1cbe-464a-90d7-f7150dc845ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcf52a3-d230-4c09-8be9-c7cdf5f8a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "labels_file_path = \"./data/\"\n",
    "\n",
    "\n",
    "def load_file(file_name: str):\n",
    "    with open(f\"{labels_file_path}{file_name}\") as json_file:\n",
    "        file_decoded = json.load(json_file)\n",
    "    return file_decoded\n",
    "\n",
    "\n",
    "sections_NAF = load_file(\"sections_codes_naf.json\")\n",
    "\n",
    "\n",
    "def format_nom_complet(\n",
    "    nom_commercial=None,\n",
    "    nom=None,\n",
    "    nom_usage=None,\n",
    "    nom_raison_sociale=None,\n",
    "    sigle=None,\n",
    "    prenom=None,\n",
    ") -> str:\n",
    "    name = \"\"\n",
    "    if nom_raison_sociale:\n",
    "        name += nom_raison_sociale + \" \"\n",
    "    if nom_commercial:\n",
    "        name += nom_commercial + \" \"\n",
    "        \n",
    "    # if there is no official company name (typically for individual company)\n",
    "    if not name:\n",
    "        if prenom or nom or nom_usage:\n",
    "            if nom_usage:\n",
    "                formatted_name = f\" {nom_usage} ({nom})\" if nom else f\" {nom_usage}\"\n",
    "            else:\n",
    "                formatted_name = f\" {nom}\" if nom else \"\"\n",
    "\n",
    "            name = f\"{prenom if prenom else ''}{formatted_name}\" + \" \"\n",
    "\n",
    "    if sigle:\n",
    "        name += f\"({sigle})\"\n",
    "    return name.lower().strip()\n",
    "\n",
    "# Entrepreneur individuel\n",
    "def is_entrepreneur_individuel(nature_juridique_unite_legale):\n",
    "    if nature_juridique_unite_legale in [\"1\", \"10\", \"1000\"]:\n",
    "        return \"true\"\n",
    "    else:\n",
    "        return \"false\"\n",
    "\n",
    "\n",
    "# Section activité principale\n",
    "def label_section_from_activite(activite_principale_unite_legale):\n",
    "    if activite_principale_unite_legale is not None:\n",
    "        code_naf = activite_principale_unite_legale[:2]\n",
    "        section_activite_principale = (\n",
    "            sections_NAF[code_naf] if code_naf in sections_NAF else None\n",
    "        )\n",
    "        return section_activite_principale\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Adresse complète\n",
    "def format_adresse_complete(\n",
    "    complement_adresse,\n",
    "    numero_voie,\n",
    "    indice_repetition,\n",
    "    type_voie,\n",
    "    libelle_voie,\n",
    "    libelle_commune,\n",
    "    libelle_cedex,\n",
    "    distribution_speciale,\n",
    "    commune,\n",
    "    cedex,\n",
    "    libelle_commune_etranger,\n",
    "    libelle_pays_etranger,\n",
    "):\n",
    "    col_list = [\n",
    "        complement_adresse,\n",
    "        numero_voie,\n",
    "        indice_repetition,\n",
    "        type_voie,\n",
    "        libelle_voie,\n",
    "        distribution_speciale,\n",
    "    ]\n",
    "    adresse = \"\"\n",
    "    for column in col_list:\n",
    "        if column:\n",
    "            adresse = adresse + \" \" + column\n",
    "    if cedex is None:\n",
    "        if commune is None:\n",
    "            adresse = adresse\n",
    "        else:\n",
    "            adresse = (\n",
    "                adresse\n",
    "                + \" \"\n",
    "                + get_empty_string_if_none(commune)\n",
    "                + \" \"\n",
    "                + get_empty_string_if_none(libelle_commune)\n",
    "            )\n",
    "    else:\n",
    "        adresse = (\n",
    "            adresse\n",
    "            + \" \"\n",
    "            + get_empty_string_if_none(cedex)\n",
    "            + \" \"\n",
    "            + get_empty_string_if_none(libelle_cedex)\n",
    "        )\n",
    "    etranger_list = [libelle_commune_etranger, libelle_pays_etranger]\n",
    "    for column in etranger_list:\n",
    "        if column:\n",
    "            adresse = adresse + \" \" + column if column != \"\" else \"\"\n",
    "    return adresse.strip()\n",
    "\n",
    "\n",
    "# Département\n",
    "def format_departement(commune):\n",
    "    departement = (\n",
    "        str(commune)[:3]\n",
    "        if str(commune)[:2] == \"97\"\n",
    "        else (None if commune is None else str(commune)[:2])\n",
    "    )\n",
    "    return departement\n",
    "\n",
    "\n",
    "# Coordonnées\n",
    "def format_coordonnees(longitude, latitude):\n",
    "    coordonnees = (\n",
    "        None if (longitude is None) or (latitude is None) else f\"{latitude},{longitude}\"\n",
    "    )\n",
    "    return coordonnees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca65059-cd6f-4e5f-96ce-e856fb3f8eb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create elastic index\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/elasticsearch/create_sirene_index.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b392ec-7e58-4b64-87e1-6067847be97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "from elasticsearch_dsl import Index, connections\n",
    "\n",
    "\n",
    "class ElasticCreateSiret:\n",
    "    \"\"\"\n",
    "    Create elasticsearch Index\n",
    "    :param elastic_url: endpoint url of elasticsearch\n",
    "    :type elastic_url: str\n",
    "    :param elastic_index: index to create\n",
    "    :type elastic_index: str\n",
    "    :param elastic_index_shards: number of shards for index\n",
    "    :type elastic_index_shards: int\n",
    "    :param elastic_user: user for elasticsearch\n",
    "    :type elastic_user: str\n",
    "    :param elastic_password: password for elasticsearch\n",
    "    :type elastic_password: str\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        elastic_url: Optional[str] = None,\n",
    "        elastic_index: Optional[str] = None,\n",
    "        elastic_user: Optional[str] = None,\n",
    "        elastic_password: Optional[str] = None,\n",
    "        elastic_bulk_size: Optional[int] = 1500,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        self.elastic_url = elastic_url\n",
    "        self.elastic_index = elastic_index\n",
    "        self.elastic_user = elastic_user\n",
    "        self.elastic_password = elastic_password\n",
    "        self.elastic_bulk_size = elastic_bulk_size\n",
    "\n",
    "        # initiate the default connection to elasticsearch\n",
    "        connections.create_connection(\n",
    "            hosts=[self.elastic_url],\n",
    "            http_auth=(self.elastic_user, self.elastic_password),\n",
    "            retry_on_timeout=True,\n",
    "        )\n",
    "\n",
    "        self.elastic_connection = connections.get_connection()\n",
    "        self.elastic_health = self.elastic_connection.cluster.health()\n",
    "        self.elastic_status = self.elastic_health[\"status\"]\n",
    "        self.elastic_mapping = self.elastic_connection.indices.get_mapping()\n",
    "\n",
    "        logging.info(\"Elasticsearch connection initiated!\")\n",
    "\n",
    "    def check_health(self):\n",
    "        if self.elastic_status not in (\"green\", \"yellow\"):\n",
    "            raise Exception(\n",
    "                f\"Cluster status is {self.elastic_status}, not green nor yellow!!\"\n",
    "            )\n",
    "        else:\n",
    "            logging.info(f\"Cluster status is functional: {self.elastic_status}\")\n",
    "\n",
    "    def execute(self):\n",
    "\n",
    "        self.check_health()\n",
    "\n",
    "        if not self.elastic_url:\n",
    "            raise ValueError(\"Please provide elasticsearch url endpoint\")\n",
    "\n",
    "        # if self.elastic_index_shards is not None:\n",
    "        if Index(self.elastic_index).exists():\n",
    "            logging.info(f\"Index  {self.elastic_index} already exists! Deleting...\")\n",
    "            Index(self.elastic_index).delete()\n",
    "            logging.info(f\"Index {self.elastic_index} deleted!\")\n",
    "        logging.info(f\"Creating {self.elastic_index} index!\")\n",
    "        # Create the mapping in elasticsearch\n",
    "        ElasticsearchSireneIndex.init(self.elastic_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35fc78-229b-45cd-910c-2d489b4b1ba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Process unites legales\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/elasticsearch/process_unites_legales.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b958f678-3e5f-41e5-a5f1-3626e1c308d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d88fba0-a5ee-4eb5-b3fa-41d27d9ae4c0",
   "metadata": {},
   "source": [
    "### Process etablissements\n",
    "adapted from process unites legales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf90f9ee-2016-46c7-8697-14d61a0219d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def process_etablissements(chunk_etablissements_sqlite: Tuple):\n",
    "    list_etablissements_processed = []\n",
    "    for etablissement in chunk_etablissements_sqlite:\n",
    "        etablissement_processed = {\"enseignes\": [], \"adresses\":[]}\n",
    "        \n",
    "        for field in etablissement:\n",
    "            if field in [\"enseignes\", \"adresses\"]: # nested fields\n",
    "                etablissement_processed[field] = json.loads(etablissement[field])\n",
    "            else:\n",
    "                etablissement_processed[field] = etablissement[field]\n",
    "\n",
    "        # Enseignes\n",
    "        etablissement_processed[\"liste_enseignes\"] = []\n",
    "        for enseigne in etablissement_processed[\"enseignes\"]:\n",
    "            etablissement_processed[\"liste_enseignes\"].extend(\n",
    "                [enseigne[\"enseigne_1\"], enseigne[\"enseigne_2\"], enseigne[\"enseigne_3\"]]\n",
    "            )\n",
    "        etablissement_processed[\"liste_enseignes\"] = list(\n",
    "            set(filter(None, etablissement_processed[\"liste_enseignes\"]))\n",
    "        )\n",
    "        del etablissement_processed[\"enseignes\"]\n",
    "\n",
    "        # Adresses\n",
    "        etablissement_processed[\"liste_adresses\"] = []\n",
    "        for adresse in etablissement_processed[\"adresses\"]:\n",
    "            etablissement_processed[\"liste_adresses\"].append(\n",
    "                format_adresse_complete(\n",
    "                    adresse[\"complement_adresse\"],\n",
    "                    adresse[\"numero_voie\"],\n",
    "                    adresse[\"indice_repetition\"],\n",
    "                    adresse[\"type_voie\"],\n",
    "                    adresse[\"libelle_voie\"],\n",
    "                    adresse[\"libelle_commune\"],\n",
    "                    adresse[\"libelle_cedex\"],\n",
    "                    adresse[\"distribution_speciale\"],\n",
    "                    adresse[\"commune\"],\n",
    "                    adresse[\"cedex\"],\n",
    "                    adresse[\"libelle_commune_etranger\"],\n",
    "                    adresse[\"libelle_pays_etranger\"],\n",
    "                )\n",
    "            )\n",
    "        etablissement_processed[\"liste_adresses\"] = list(\n",
    "            set(filter(None, etablissement_processed[\"liste_adresses\"]))\n",
    "        )\n",
    "        del etablissement_processed[\"adresses\"]\n",
    "\n",
    "        etablissement_processed[\"adresse_etablissement\"] = format_adresse_complete(\n",
    "            etablissement_processed[\"complement_adresse\"],\n",
    "            etablissement_processed[\"numero_voie\"],\n",
    "            etablissement_processed[\"indice_repetition\"],\n",
    "            etablissement_processed[\"type_voie\"],\n",
    "            etablissement_processed[\"libelle_voie\"],\n",
    "            etablissement_processed[\"libelle_commune\"],\n",
    "            etablissement_processed[\"libelle_cedex\"],\n",
    "            etablissement_processed[\"distribution_speciale\"],\n",
    "            etablissement_processed[\"commune\"],\n",
    "            etablissement_processed[\"cedex\"],\n",
    "            etablissement_processed[\"libelle_commune_etranger\"],\n",
    "            etablissement_processed[\"libelle_pays_etranger\"],\n",
    "        )\n",
    "\n",
    "        # compute nom complet for unite legale (that is not specific to etablissement)\n",
    "        etablissement_processed[\"nom_complet\"] = format_nom_complet(\n",
    "            etablissement_processed[\"nom_commercial\"],\n",
    "            etablissement_processed[\"nom\"],\n",
    "            etablissement_processed[\"nom_usage\"],\n",
    "            etablissement_processed[\"nom_raison_sociale\"],\n",
    "            etablissement_processed[\"sigle\"],\n",
    "            etablissement_processed[\"prenom\"],\n",
    "        )\n",
    "        # Replace missing values with 0\n",
    "        etablissement_processed[\"nombre_etablissements_ouverts\"] = (\n",
    "            0\n",
    "            if \"nombre_etablissements_ouverts\" not in etablissement_processed or etablissement_processed[\"nombre_etablissements_ouverts\"] is None\n",
    "            else etablissement_processed[\"nombre_etablissements_ouverts\"]\n",
    "        )\n",
    "        #etablissement_processed[\n",
    "        #    \"is_entrepreneur_individuel\"\n",
    "       # ] = is_entrepreneur_individuel(etablissement[\"nature_juridique_etablissement\"])\n",
    "        etablissement_processed[\n",
    "            \"section_activite_principale\"\n",
    "        ] = label_section_from_activite(\n",
    "            etablissement[\"activite_principale_siege\"]\n",
    "        )\n",
    "        etablissement_processed[\"departement\"] = format_departement(\n",
    "            etablissement[\"commune\"]\n",
    "        )\n",
    "        etablissement_processed[\"coordonnees\"] = format_coordonnees(\n",
    "            etablissement[\"longitude\"], etablissement[\"latitude\"]\n",
    "        )\n",
    "        etablissement_processed[\"concat_enseigne_adresse\"] = (\n",
    "            etablissement_processed[\"liste_enseignes\"]\n",
    "            + etablissement_processed[\"liste_adresses\"]\n",
    "        )\n",
    "\n",
    "        etablissement_processed[\"concat_nom_adr_siren\"] = (\n",
    "            get_empty_string_if_none(etablissement_processed[\"nom_complet\"])\n",
    "            + \" \"\n",
    "            + get_empty_string_if_none(etablissement_processed[\"adresse_etablissement\"])\n",
    "            + \" \"\n",
    "            + get_empty_string_if_none(etablissement[\"siren\"])\n",
    "        ).strip()\n",
    "        list_etablissements_processed.append(etablissement_processed)\n",
    "    return list_etablissements_processed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a86ebd-4bd5-48d1-b369-4340b22feb13",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mapping unites legales\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/elasticsearch/mapping_sirene_index.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8234a77e-9a7b-4781-bc8a-aa06833165da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import (\n",
    "    Boolean,\n",
    "    Date,\n",
    "    Document,\n",
    "    GeoPoint,\n",
    "    Integer,\n",
    "    Keyword,\n",
    "    Text,\n",
    "    analyzer,\n",
    "    token_filter,\n",
    "    tokenizer,\n",
    ")\n",
    "\n",
    "# Define filters\n",
    "french_elision = token_filter(\n",
    "    \"french_elision\",\n",
    "    type=\"elision\",\n",
    "    articles_case=True,\n",
    "    articles=[\n",
    "        \"l\",\n",
    "        \"m\",\n",
    "        \"t\",\n",
    "        \"qu\",\n",
    "        \"n\",\n",
    "        \"s\",\n",
    "        \"j\",\n",
    "        \"d\",\n",
    "        \"c\",\n",
    "        \"jusqu\",\n",
    "        \"quoiqu\",\n",
    "        \"lorsqu\",\n",
    "        \"puisqu\",\n",
    "    ],\n",
    ")\n",
    "french_stop = token_filter(\"french_stop\", type=\"stop\", stopwords=\"_french_\")\n",
    "french_stemmer = token_filter(\"french_stemmer\", type=\"stemmer\", language=\"light_french\")\n",
    "# ignore_case option deprecated, use lowercase filter before synonym filter\n",
    "french_synonym = token_filter(\n",
    "    \"french_synonym\", type=\"synonym\", expand=True, synonyms=[]\n",
    ")\n",
    "\n",
    "# Define analyzer\n",
    "annuaire_analyzer = analyzer(\n",
    "    \"annuaire_analyzer\",\n",
    "    tokenizer=tokenizer(\"icu_tokenizer\"),\n",
    "    filter=[\n",
    "        \"lowercase\",\n",
    "        french_elision,\n",
    "        french_stop,\n",
    "        \"icu_folding\",\n",
    "        french_synonym,\n",
    "        \"asciifolding\",\n",
    "        french_stemmer,\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "class ElasticsearchSireneIndex(Document):\n",
    "    \"\"\"\n",
    "\n",
    "    Model-like class for persisting documents in elasticsearch.\n",
    "    It's a wrapper around document to create specific mappings and to add settings in\n",
    "    elasticsearch.\n",
    "\n",
    "    Class used to represent etablissements\n",
    "    \"\"\"\n",
    "\n",
    "    activite_principale_siege = Keyword()  # Add index_prefixes option\n",
    "    activite_principale_unite_legale = Keyword()\n",
    "    activite_principale_registre_metier = Keyword()\n",
    "    adresse_etablissement = Text()\n",
    "    categorie_entreprise = Text()\n",
    "    cedex = Keyword()\n",
    "    code_pays_etranger = Text()\n",
    "    code_postal = Keyword()\n",
    "    commune = Keyword()\n",
    "    complement_adresse = Text()\n",
    "    concat_enseigne_adresse = Text(analyzer=annuaire_analyzer)\n",
    "    concat_nom_adr_siren = Text(\n",
    "        analyzer=annuaire_analyzer, fields={\"keyword\": Keyword()}\n",
    "    )\n",
    "    coordonnees = GeoPoint()\n",
    "    date_creation_siege = Date()\n",
    "    date_creation_unite_legale = Date()\n",
    "    date_debut_activite_siege = Date()\n",
    "    date_mise_a_jour = Date()\n",
    "    departement = Keyword()\n",
    "    distribution_speciale = Text()\n",
    "    economie_sociale_solidaire_unite_legale = Keyword()\n",
    "    enseigne = Text()\n",
    "    etat_administratif_unite_legale = Keyword()\n",
    "    etat_administratif_etablissement = Keyword()\n",
    "    geo_adresse = Text(analyzer=annuaire_analyzer)\n",
    "    geo_id = Keyword()\n",
    "    identifiant_association_unite_legale = Keyword()\n",
    "    indice_repetition = Text()\n",
    "    is_entrepreneur_individuel = Boolean()\n",
    "    is_siege = Boolean()\n",
    "    latitude = Text()\n",
    "    libelle_cedex = Text()\n",
    "    libelle_commune = Text()\n",
    "    libelle_commune_etranger = Text()\n",
    "    libelle_pays_etranger = Text()\n",
    "    libelle_voie = Text()\n",
    "    liste_adresses = Text(analyzer=annuaire_analyzer)\n",
    "    liste_enseignes = Text(analyzer=annuaire_analyzer)\n",
    "    longitude = Text()\n",
    "    nature_juridique_unite_legale = Integer()\n",
    "    nom = Text()\n",
    "    nom_complet = Text(analyzer=annuaire_analyzer, fields={\"keyword\": Keyword()})\n",
    "    nom_raison_sociale = Text()\n",
    "  #  nombre_etablissements = Integer()  # NaN can't be stored in an integer array\n",
    "    nombre_etablissements_ouverts = Integer()\n",
    "    numero_voie = Text()\n",
    "    section_activite_principale = Keyword()\n",
    "    sigle = Keyword()\n",
    "    siren = Keyword(required=True)\n",
    "    siret_siege = Keyword(required=True)\n",
    "    type_voie = Text()\n",
    "    tranche_effectif_salarie_siege = Keyword()\n",
    "    tranche_effectif_salarie_unite_legale = Keyword()\n",
    "\n",
    "    class Index:\n",
    "        settings = {\"number_of_shards\": 1, \"number_of_replicas\": 0}\n",
    "        name = \"siret\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2be50-69d3-41e0-96c1-a5c779d37aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "541179bd-5ee8-44d8-be79-cb46bda22e6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fill database and index\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/task_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf7d1cf-4a49-4b36-ae83-17a728647fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unite_legale_table(**kwargs):\n",
    "    siren_db_conn, siren_db_cursor = connect_to_db()\n",
    "    siren_db_cursor.execute(\"\"\"DROP TABLE IF EXISTS unite_legale\"\"\")\n",
    "    siren_db_cursor.execute(\n",
    "        \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS unite_legale\n",
    "        (\n",
    "            siren,\n",
    "            date_creation_unite_legale,\n",
    "            sigle,\n",
    "            prenom,\n",
    "            identifiant_association_unite_legale,\n",
    "            tranche_effectif_salarie_unite_legale,\n",
    "            date_mise_a_jour_unite_legale,\n",
    "            categorie_entreprise,\n",
    "            etat_administratif_unite_legale,\n",
    "            nom,\n",
    "            nom_usage,\n",
    "            nom_raison_sociale,\n",
    "            nature_juridique_unite_legale,\n",
    "            activite_principale_unite_legale,\n",
    "            economie_sociale_solidaire_unite_legale\n",
    "        )\n",
    "    \"\"\"\n",
    "    )\n",
    "    siren_db_cursor.execute(\n",
    "        \"\"\"\n",
    "        CREATE UNIQUE INDEX index_siren\n",
    "        ON unite_legale (siren);\n",
    "        \"\"\"\n",
    "    )\n",
    "    url = \"https://files.data.gouv.fr/insee-sirene/StockUniteLegale_utf8.zip\"\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    open(DATA_DIR + \"StockUniteLegale_utf8.zip\", \"wb\").write(r.content)\n",
    "    shutil.unpack_archive(DATA_DIR + \"StockUniteLegale_utf8.zip\", DATA_DIR)\n",
    "    df_iterator = pd.read_csv(\n",
    "        DATA_DIR + \"StockUniteLegale_utf8.csv\", chunksize=100000, dtype=str\n",
    "    )\n",
    "    # Insert rows in database by chunk\n",
    "    for i, df_unite_legale in enumerate(df_iterator):\n",
    "        df_unite_legale = df_unite_legale[\n",
    "            [\n",
    "                \"siren\",\n",
    "                \"dateCreationUniteLegale\",\n",
    "                \"sigleUniteLegale\",\n",
    "                \"prenom1UniteLegale\",\n",
    "                \"identifiantAssociationUniteLegale\",\n",
    "                \"trancheEffectifsUniteLegale\",\n",
    "                \"dateDernierTraitementUniteLegale\",\n",
    "                \"categorieEntreprise\",\n",
    "                \"etatAdministratifUniteLegale\",\n",
    "                \"nomUniteLegale\",\n",
    "                \"nomUsageUniteLegale\",\n",
    "                \"denominationUniteLegale\",\n",
    "                \"categorieJuridiqueUniteLegale\",\n",
    "                \"activitePrincipaleUniteLegale\",\n",
    "                \"economieSocialeSolidaireUniteLegale\",\n",
    "            ]\n",
    "        ]\n",
    "        # Rename columns\n",
    "        df_unite_legale = df_unite_legale.rename(\n",
    "            columns={\n",
    "                \"dateCreationUniteLegale\": \"date_creation_unite_legale\",\n",
    "                \"sigleUniteLegale\": \"sigle\",\n",
    "                \"prenom1UniteLegale\": \"prenom\",\n",
    "                \"trancheEffectifsUniteLegale\": \"tranche_effectif_salarie_unite_legale\",\n",
    "                \"dateDernierTraitementUniteLegale\": \"date_mise_a_jour_unite_legale\",\n",
    "                \"categorieEntreprise\": \"categorie_entreprise\",\n",
    "                \"etatAdministratifUniteLegale\": \"etat_administratif_unite_legale\",\n",
    "                \"nomUniteLegale\": \"nom\",\n",
    "                \"nomUsageUniteLegale\": \"nom_usage\",\n",
    "                \"denominationUniteLegale\": \"nom_raison_sociale\",\n",
    "                \"categorieJuridiqueUniteLegale\": \"nature_juridique_unite_legale\",\n",
    "                \"activitePrincipaleUniteLegale\": \"activite_principale_unite_legale\",\n",
    "                \"economieSocialeSolidaireUniteLegale\": \"economie_sociale_solidaire_\"\n",
    "                \"unite_legale\",\n",
    "                \"identifiantAssociationUniteLegale\": \"identifiant_association_\"\n",
    "                \"unite_legale\",\n",
    "            }\n",
    "        )\n",
    "        df_unite_legale.to_sql(\n",
    "            \"unite_legale\", siren_db_conn, if_exists=\"append\", index=False\n",
    "        )\n",
    "\n",
    "        for row in siren_db_cursor.execute(\"\"\"SELECT COUNT() FROM unite_legale\"\"\"):\n",
    "            logging.info(\n",
    "                f\"************ {row} records have been added to the unite_legale table!\"\n",
    "            )\n",
    "\n",
    "    del df_unite_legale\n",
    "\n",
    "    for count_unites_legales in siren_db_cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT COUNT()\n",
    "        FROM unite_legale\n",
    "        \"\"\"\n",
    "    ):\n",
    "        logging.info(\n",
    "            f\"************ {count_unites_legales} records have been added to the \"\n",
    "            f\"unite_legale table!\"\n",
    "        )\n",
    "    commit_and_close_conn(siren_db_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6e7359-6ca6-488e-853d-ce78319fc837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from elasticsearch_dsl import connections\n",
    "#from minio import Minio\n",
    "\n",
    "DATA_DIR = \"/home/jovyan/work/matchSIRET/indexation/data/\"\n",
    "DATABASE_LOCATION = DATA_DIR + \"sirene.db\"\n",
    "ELASTIC_BULK_SIZE = 1500\n",
    "\n",
    "ELASTIC_PASSWORD = \"\"\n",
    "ELASTIC_URL = \"http://elasticsearch-master:9200\"\n",
    "ELASTIC_USER = \"\"\n",
    "\n",
    "\n",
    "# Connect to database\n",
    "def connect_to_db():\n",
    "    siret_db_conn = sqlite3.connect(DATABASE_LOCATION)\n",
    "    logging.info(\"******************* Connecting to database! *******************\")\n",
    "    siret_db_cursor = siret_db_conn.cursor()\n",
    "    return siret_db_conn, siret_db_cursor\n",
    "\n",
    "\n",
    "def commit_and_close_conn(siret_db_conn):\n",
    "    siret_db_conn.commit()\n",
    "    siret_db_conn.close()\n",
    "\n",
    "\n",
    "def create_sqlite_database():\n",
    "    os.makedirs(os.path.dirname(DATA_DIR), exist_ok=True)\n",
    "    if os.path.exists(DATABASE_LOCATION):\n",
    "        os.remove(DATABASE_LOCATION)\n",
    "        logging.info(\n",
    "            \"******************** Existing database removed from {DATABASE_LOCATION}\"\n",
    "        )\n",
    "    siren_db_conn = sqlite3.connect(DATABASE_LOCATION)\n",
    "    logging.info(\n",
    "        \"******************* Creating and connecting to database! *******************\"\n",
    "    )\n",
    "    commit_and_close_conn(siren_db_conn)\n",
    "\n",
    "\n",
    "def create_etablissement_table():\n",
    "    siret_db_conn, siret_db_cursor = connect_to_db()\n",
    "    # Create list of departement zip codes\n",
    "    all_deps = [\n",
    "        *\"-0\".join(list(str(x) for x in range(0, 10))).split(\"-\")[1:],\n",
    "        *list(str(x) for x in range(10, 20)),\n",
    "        *[\"2A\", \"2B\"],\n",
    "        *list(str(x) for x in range(21, 96)),\n",
    "        *\"-7510\".join(list(str(x) for x in range(0, 10))).split(\"-\")[1:],\n",
    "        *\"-751\".join(list(str(x) for x in range(9, 21))).split(\"-\")[1:],\n",
    "        *[\"971\", \"972\", \"973\", \"974\", \"976\", \"98\"],\n",
    "        *[\"\"],\n",
    "    ]\n",
    "    # Remove Paris zip code\n",
    "    all_deps.remove(\"75\")\n",
    "\n",
    "    # Create database\n",
    "    siret_db_cursor.execute(\"\"\"DROP TABLE IF EXISTS siret\"\"\")\n",
    "    siret_db_cursor.execute(\n",
    "        \"\"\"CREATE TABLE IF NOT EXISTS siret\n",
    "            (\n",
    "            id INTEGER NOT NULL PRIMARY KEY,\n",
    "            siren,\n",
    "            siret,\n",
    "            date_creation,\n",
    "            tranche_effectif_salarie,\n",
    "            activite_principale_registre_metier,\n",
    "            is_siege,\n",
    "            numero_voie,\n",
    "            type_voie,\n",
    "            libelle_voie,\n",
    "            code_postal,\n",
    "            libelle_cedex,\n",
    "            libelle_commune,\n",
    "            commune,\n",
    "            complement_adresse,\n",
    "            complement_adresse_2,\n",
    "            numero_voie_2,\n",
    "            indice_repetition_2,\n",
    "            type_voie_2,\n",
    "            libelle_voie_2,\n",
    "            commune_2,\n",
    "            libelle_commune_2,\n",
    "            cedex_2,\n",
    "            libelle_cedex_2,\n",
    "            cedex,\n",
    "            date_debut_activite,\n",
    "            distribution_speciale,\n",
    "            distribution_speciale_2,\n",
    "            etat_administratif_etablissement,\n",
    "            enseigne_1,\n",
    "            enseigne_2,\n",
    "            enseigne_3,\n",
    "            activite_principale,\n",
    "            indice_repetition,\n",
    "            nom_commercial,\n",
    "            libelle_commune_etranger,\n",
    "            code_pays_etranger,\n",
    "            libelle_pays_etranger,\n",
    "            libelle_commune_etranger_2,\n",
    "            code_pays_etranger_2,\n",
    "            libelle_pays_etranger_2,\n",
    "            longitude,\n",
    "            latitude,\n",
    "            geo_adresse,\n",
    "            geo_id)\n",
    "            \"\"\"\n",
    "    )\n",
    "     # TODO : add in files.data.gouv the field sigle_unite_legale ?\n",
    "    siret_db_cursor.execute(\n",
    "        \"\"\"\n",
    "        CREATE INDEX index_siret\n",
    "        ON siret (siret);\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Upload geo data by departement\n",
    "    for dep in all_deps:\n",
    "        url = f\"https://files.data.gouv.fr/geo-sirene/last/dep/geo_siret_{dep}.csv.gz\"\n",
    "        print(url)\n",
    "        df_dep = pd.read_csv(\n",
    "            url,\n",
    "            compression=\"gzip\",\n",
    "            dtype=str,\n",
    "            usecols=[\n",
    "                \"siren\",\n",
    "                \"siret\",\n",
    "                \"dateCreationEtablissement\",\n",
    "                \"trancheEffectifsEtablissement\",\n",
    "                \"activitePrincipaleRegistreMetiersEtablissement\",\n",
    "                \"etablissementSiege\",\n",
    "                \"numeroVoieEtablissement\",\n",
    "                \"libelleVoieEtablissement\",\n",
    "                \"codePostalEtablissement\",\n",
    "                \"libelleCommuneEtablissement\",\n",
    "                \"libelleCedexEtablissement\",\n",
    "                \"typeVoieEtablissement\",\n",
    "                \"codeCommuneEtablissement\",\n",
    "                \"codeCedexEtablissement\",\n",
    "                \"complementAdresseEtablissement\",\n",
    "                \"distributionSpecialeEtablissement\",\n",
    "                \"complementAdresse2Etablissement\",\n",
    "                \"indiceRepetition2Etablissement\",\n",
    "                \"libelleCedex2Etablissement\",\n",
    "                \"codeCedex2Etablissement\",\n",
    "                \"numeroVoie2Etablissement\",\n",
    "                \"typeVoie2Etablissement\",\n",
    "                \"libelleVoie2Etablissement\",\n",
    "                \"codeCommune2Etablissement\",\n",
    "                \"libelleCommune2Etablissement\",\n",
    "                \"distributionSpeciale2Etablissement\",\n",
    "                \"dateDebut\",\n",
    "                \"etatAdministratifEtablissement\",\n",
    "                \"enseigne1Etablissement\",\n",
    "                \"enseigne1Etablissement\",\n",
    "                \"enseigne2Etablissement\",\n",
    "                \"enseigne3Etablissement\",\n",
    "                \"denominationUsuelleEtablissement\",\n",
    "         #       \"sigleUniteLegale\",\n",
    "                \"activitePrincipaleEtablissement\",\n",
    "                \"geo_adresse\",\n",
    "                \"geo_id\",\n",
    "                \"longitude\",\n",
    "                \"latitude\",\n",
    "                \"indiceRepetitionEtablissement\",\n",
    "                \"libelleCommuneEtrangerEtablissement\",\n",
    "                \"codePaysEtrangerEtablissement\",\n",
    "                \"libellePaysEtrangerEtablissement\",\n",
    "                \"libelleCommuneEtranger2Etablissement\",\n",
    "                \"codePaysEtranger2Etablissement\",\n",
    "                \"libellePaysEtranger2Etablissement\",\n",
    "            ],\n",
    "        )\n",
    "        df_dep = df_dep.rename(\n",
    "            columns={\n",
    "                \"dateCreationEtablissement\": \"date_creation\",\n",
    "                \"trancheEffectifsEtablissement\": \"tranche_effectif_salarie\",\n",
    "                \"activitePrincipaleRegistreMetiersEtablissement\": \"activite_principale\"\n",
    "                \"_registre_metier\",\n",
    "                \"etablissementSiege\": \"is_siege\",\n",
    "                \"numeroVoieEtablissement\": \"numero_voie\",\n",
    "                \"typeVoieEtablissement\": \"type_voie\",\n",
    "                \"libelleVoieEtablissement\": \"libelle_voie\",\n",
    "                \"codePostalEtablissement\": \"code_postal\",\n",
    "                \"libelleCedexEtablissement\": \"libelle_cedex\",\n",
    "                \"libelleCommuneEtablissement\": \"libelle_commune\",\n",
    "                \"codeCommuneEtablissement\": \"commune\",\n",
    "                \"complementAdresseEtablissement\": \"complement_adresse\",\n",
    "                \"complementAdresse2Etablissement\": \"complement_adresse_2\",\n",
    "                \"numeroVoie2Etablissement\": \"numero_voie_2\",\n",
    "                \"indiceRepetition2Etablissement\": \"indice_repetition_2\",\n",
    "                \"typeVoie2Etablissement\": \"type_voie_2\",\n",
    "                \"libelleVoie2Etablissement\": \"libelle_voie_2\",\n",
    "                \"codeCommune2Etablissement\": \"commune_2\",\n",
    "                \"libelleCommune2Etablissement\": \"libelle_commune_2\",\n",
    "                \"codeCedex2Etablissement\": \"cedex_2\",\n",
    "                \"libelleCedex2Etablissement\": \"libelle_cedex_2\",\n",
    "                \"codeCedexEtablissement\": \"cedex\",\n",
    "                \"dateDebut\": \"date_debut_activite\",\n",
    "                \"distributionSpecialeEtablissement\": \"distribution_speciale\",\n",
    "                \"distributionSpeciale2Etablissement\": \"distribution_speciale_2\",\n",
    "                \"etatAdministratifEtablissement\": \"etat_administratif_etablissement\",\n",
    "                \"enseigne1Etablissement\": \"enseigne_1\",\n",
    "                \"enseigne2Etablissement\": \"enseigne_2\",\n",
    "                \"enseigne3Etablissement\": \"enseigne_3\",\n",
    "                \"activitePrincipaleEtablissement\": \"activite_principale\",\n",
    "                \"indiceRepetitionEtablissement\": \"indice_repetition\",\n",
    "                \"denominationUsuelleEtablissement\": \"nom_commercial\",\n",
    "            #    \"sigleUniteLegale\": \"sigle_unite_legale\",\n",
    "                \"libelleCommuneEtrangerEtablissement\": \"libelle_commune_etranger\",\n",
    "                \"codePaysEtrangerEtablissement\": \"code_pays_etranger\",\n",
    "                \"libellePaysEtrangerEtablissement\": \"libelle_pays_etranger\",\n",
    "                \"libelleCommuneEtranger2Etablissement\": \"libelle_commune_etranger_2\",\n",
    "                \"codePaysEtranger2Etablissement\": \"code_pays_etranger_2\",\n",
    "                \"libellePaysEtranger2Etablissement\": \"libelle_pays_etranger_2\",\n",
    "            }\n",
    "        )\n",
    "        df_dep.to_sql(\"siret\", siret_db_conn, if_exists=\"append\", index=False)\n",
    "        siret_db_conn.commit()\n",
    "        for row in siret_db_cursor.execute(\"\"\"SELECT COUNT() FROM siret\"\"\"):\n",
    "            logging.info(\n",
    "                f\"************ {row} records have been added to the siret table!\"\n",
    "            )\n",
    "    del df_dep\n",
    "    commit_and_close_conn(siret_db_conn)\n",
    "\n",
    "\n",
    "def count_nombre_etablissements():\n",
    "    # Connect to database\n",
    "    siren_db_conn, siren_db_cursor = connect_to_db()\n",
    "    # Create a count table\n",
    "    siren_db_cursor.execute(\"\"\"DROP TABLE IF EXISTS count_etab\"\"\")\n",
    "    siren_db_cursor.execute(\n",
    "        \"\"\"CREATE TABLE count_etab (siren VARCHAR(10), count INTEGER)\"\"\"\n",
    "    )\n",
    "    # Create index\n",
    "    siren_db_cursor.execute(\n",
    "        \"\"\"\n",
    "        CREATE UNIQUE INDEX index_count_siren\n",
    "        ON count_etab (siren);\n",
    "        \"\"\"\n",
    "    )\n",
    "    siren_db_cursor.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO count_etab (siren, count)\n",
    "        SELECT siren, count(*) as count\n",
    "        FROM siret GROUP BY siren;\n",
    "        \"\"\"\n",
    "    )\n",
    "    commit_and_close_conn(siren_db_conn)\n",
    "\n",
    "\n",
    "def count_nombre_etablissements_ouverts():\n",
    "    siret_db_conn, siret_db_cursor = connect_to_db()\n",
    "    siret_db_cursor.execute(\"\"\"DROP TABLE IF EXISTS count_etab_ouvert\"\"\")\n",
    "    siret_db_cursor.execute(\n",
    "        \"\"\"CREATE TABLE count_etab_ouvert (siren VARCHAR(10), count INTEGER)\"\"\"\n",
    "    )\n",
    "    siret_db_cursor.execute(\n",
    "        \"\"\"\n",
    "        CREATE UNIQUE INDEX index_count_ouvert_siren\n",
    "        ON count_etab_ouvert (siren);\n",
    "        \"\"\"\n",
    "    )\n",
    "    siret_db_cursor.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO count_etab_ouvert (siren, count)\n",
    "        SELECT siren, count(*) as count\n",
    "        FROM siret\n",
    "        WHERE etat_administratif_etablissement = 'A' GROUP BY siren;\n",
    "        \"\"\"\n",
    "    )\n",
    "    commit_and_close_conn(siret_db_conn)\n",
    "\n",
    "\n",
    "\n",
    "def create_elastic_index(**kwargs):\n",
    "    elastic_index = \"siret\"\n",
    "    logging.info(f\"******************** Index to create: {elastic_index}\")\n",
    "    create_index = ElasticCreateSiret(\n",
    "        elastic_url=ELASTIC_URL,\n",
    "        elastic_index=elastic_index,\n",
    "        elastic_user=ELASTIC_USER,\n",
    "        elastic_password=ELASTIC_PASSWORD,\n",
    "        elastic_bulk_size=ELASTIC_BULK_SIZE,\n",
    "    )\n",
    "    create_index.execute()\n",
    "\n",
    "\n",
    "def fill_elastic_index(**kwargs):\n",
    "    elastic_index = \"siret\"\n",
    "    siret_db_conn, siret_db_cursor = connect_to_db()\n",
    "\n",
    "    \n",
    "    siret_db_cursor.execute(\n",
    "        \"\"\"SELECT\n",
    "        ul.siren,\n",
    "        st.siret as siret,\n",
    "        st.nom_commercial as nom_commercial,\n",
    "        st.date_creation as date_creation_siege,\n",
    "        st.tranche_effectif_salarie as tranche_effectif_salarie_siege,\n",
    "        st.date_debut_activite as date_debut_activite_siege,\n",
    "        st.etat_administratif_etablissement as etat_administratif_siege,\n",
    "        st.activite_principale as activite_principale_siege,\n",
    "        st.complement_adresse as complement_adresse,\n",
    "        st.numero_voie as numero_voie,\n",
    "        st.indice_repetition as indice_repetition,\n",
    "        st.type_voie as type_voie,\n",
    "        st.libelle_voie as libelle_voie,\n",
    "        st.distribution_speciale as distribution_speciale,\n",
    "        st.cedex as cedex,\n",
    "        st.libelle_cedex as libelle_cedex,\n",
    "        st.commune as commune,\n",
    "        st.libelle_commune as libelle_commune,\n",
    "        st.code_pays_etranger as code_pays_etranger,\n",
    "        st.libelle_commune_etranger as libelle_commune_etranger,\n",
    "        st.libelle_pays_etranger as libelle_pays_etranger,\n",
    "        st.code_postal as code_postal,\n",
    "        st.geo_id as geo_id,\n",
    "        st.longitude as longitude,\n",
    "        st.latitude as latitude,\n",
    "        st.activite_principale_registre_metier as activite_principale_registre_metier,\n",
    "        ul.date_creation_unite_legale as date_creation_unite_legale,\n",
    "        ul.tranche_effectif_salarie_unite_legale as tranche_effectif_salarie_unite_legale,\n",
    "        ul.date_mise_a_jour_unite_legale as date_mise_a_jour,\n",
    "        ul.categorie_entreprise as categorie_entreprise,\n",
    "        ul.etat_administratif_unite_legale as etat_administratif_unite_legale,\n",
    "        ul.nom_raison_sociale as nom_raison_sociale,\n",
    "        ul.nature_juridique_unite_legale as nature_juridique_unite_legale,\n",
    "        ul.activite_principale_unite_legale as activite_principale_unite_legale,\n",
    "        ul.economie_sociale_solidaire_unite_legale as\n",
    "        economie_sociale_solidaire_unite_legale,\n",
    "        (SELECT count FROM count_etab_ouvert ceo WHERE ceo.siren = st.siren LIMIT 10) as\n",
    "        nombre_etablissements_ouverts,\n",
    "        (SELECT json_group_array(\n",
    "            json_object(\n",
    "                'enseigne_1', enseigne_1,\n",
    "                'enseigne_2', enseigne_2,\n",
    "                'enseigne_3', enseigne_3)\n",
    "            ) FROM\n",
    "            (SELECT enseigne_1, enseigne_2, enseigne_3 from siret\n",
    "            WHERE siren = st.siren LIMIT 10)\n",
    "        ) as enseignes,\n",
    "        (SELECT json_group_array(\n",
    "            json_object(\n",
    "            'complement_adresse', complement_adresse,\n",
    "            'numero_voie', numero_voie,\n",
    "            'indice_repetition', indice_repetition,\n",
    "            'type_voie', type_voie,\n",
    "            'libelle_voie', libelle_voie,\n",
    "            'libelle_commune', libelle_commune,\n",
    "            'libelle_cedex', libelle_cedex,\n",
    "            'distribution_speciale', distribution_speciale,\n",
    "            'commune', commune,\n",
    "            'cedex', cedex,\n",
    "            'libelle_commune_etranger', libelle_commune_etranger,\n",
    "            'libelle_pays_etranger', libelle_pays_etranger)\n",
    "            ) FROM\n",
    "            (SELECT complement_adresse, numero_voie, indice_repetition,\n",
    "            type_voie, libelle_voie, libelle_commune, distribution_speciale,\n",
    "            commune, cedex, libelle_commune_etranger, libelle_pays_etranger\n",
    "            FROM siret\n",
    "            WHERE siren = st.siren LIMIT 10)\n",
    "            ) as adresses,\n",
    "            ul.sigle as sigle,\n",
    "            ul.prenom as prenom,\n",
    "            ul.nom as nom,\n",
    "            ul.nom_usage as nom_usage,\n",
    "            st.is_siege as is_siege\n",
    "        FROM\n",
    "            siret st\n",
    "        LEFT JOIN\n",
    "            unite_legale ul\n",
    "        ON\n",
    "            ul.siren = st.siren\n",
    "        LIMIT 10\n",
    "        ;\"\"\"  # noqa\n",
    "    )\n",
    "    \n",
    "    connections.create_connection(\n",
    "        hosts=[ELASTIC_URL],\n",
    "        http_auth=(ELASTIC_USER, ELASTIC_PASSWORD),\n",
    "        retry_on_timeout=True,\n",
    "    )\n",
    "    elastic_connection = connections.get_connection()\n",
    "\n",
    "    \n",
    "    doc_count = index_etablissements_by_chunk(\n",
    "        cursor=siret_db_cursor,\n",
    "        elastic_connection=elastic_connection,\n",
    "        elastic_bulk_size=ELASTIC_BULK_SIZE,\n",
    "        elastic_index=elastic_index,\n",
    "    )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa5533-9d87-4b01-91c6-05844ee668d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Indexing chunks of unite legale\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/elasticsearch/indexing_unite_legale.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e7382-700b-4e7f-b37a-a5934345817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from elasticsearch.helpers import parallel_bulk\n",
    "\n",
    "\n",
    "def elasticsearch_doc_generator(data):\n",
    "    # Serialize the instance into a dictionary so that it can be saved in elasticsearch.\n",
    "    for index, document in enumerate(data):\n",
    "        yield ElasticsearchSireneIndex(\n",
    "            meta={\"id\": document[\"siret\"]}, **document\n",
    "        ).to_dict(include_meta=True)\n",
    "\n",
    "\n",
    "def index_unites_legales_by_chunk(\n",
    "    cursor, elastic_connection, elastic_bulk_size, elastic_index\n",
    "):\n",
    "    logger = 0\n",
    "    chunk_unites_legales_sqlite = 1\n",
    "    while chunk_unites_legales_sqlite:\n",
    "        chunk_unites_legales_sqlite = cursor.fetchmany(elastic_bulk_size)\n",
    "        unite_legale_columns = tuple([x[0] for x in cursor.description])\n",
    "        liste_unites_legales_sqlite = []\n",
    "        # Group all fetched unites_legales from sqlite in one list\n",
    "        for unite_legale in chunk_unites_legales_sqlite:\n",
    "            liste_unites_legales_sqlite.append(\n",
    "                {\n",
    "                    unite_legale_columns: value\n",
    "                    for unite_legale_columns, value in zip(\n",
    "                        unite_legale_columns, unite_legale\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "        liste_unites_legales_sqlite = tuple(liste_unites_legales_sqlite)\n",
    "\n",
    "        chunk_unites_legales_processed = process_unites_legales(\n",
    "            liste_unites_legales_sqlite\n",
    "        )\n",
    "        logger += 1\n",
    "        if logger % 1000 == 0:\n",
    "            logging.info(f\"logger={logger}\")\n",
    "        try:\n",
    "            chunk_doc_generator = elasticsearch_doc_generator(\n",
    "                chunk_unites_legales_processed\n",
    "            )\n",
    "            # Bulk index documents into elasticsearch using the parallel version of the\n",
    "            # bulk helper that runs in multiple threads\n",
    "            # The bulk helper accept an instance of Elasticsearch class and an\n",
    "            # iterable, a generator in our case\n",
    "            for success, details in parallel_bulk(\n",
    "                elastic_connection, chunk_doc_generator, chunk_size=elastic_bulk_size\n",
    "            ):\n",
    "                if not success:\n",
    "                    raise Exception(f\"A file_access document failed: {details}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to send to Elasticsearch: {e}\")\n",
    "        doc_count = elastic_connection.cat.count(\n",
    "            index=elastic_index, params={\"format\": \"json\"}\n",
    "        )[0][\"count\"]\n",
    "        logging.info(f\"Number of documents indexed: {doc_count}\")\n",
    "    return doc_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1c7ae-588d-442e-b253-d72ae0d10415",
   "metadata": {},
   "source": [
    "### Indexing chunks of etablissements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b1a04c-7d8c-4d5a-95d0-b0c417c9bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_etablissements_by_chunk(\n",
    "    cursor, elastic_connection, elastic_bulk_size, elastic_index\n",
    "):\n",
    "    logger = 0\n",
    "    chunk_etablissements_sqlite = 1\n",
    "    while chunk_etablissements_sqlite:\n",
    "        chunk_etablissements_sqlite = cursor.fetchmany(elastic_bulk_size)\n",
    "        etablissements_columns = tuple([x[0] for x in cursor.description])\n",
    "        liste_etablissements_sqlite = []\n",
    "        # Group all fetched etablissements from sqlite in one list\n",
    "        for etablissement in chunk_etablissements_sqlite:\n",
    "            liste_etablissements_sqlite.append(\n",
    "                {\n",
    "                    etablissement_column: value\n",
    "                    for etablissement_column, value in zip(\n",
    "                        etablissements_columns, etablissement\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "        liste_etablissements_sqlite = tuple(liste_etablissements_sqlite)\n",
    "\n",
    "        # TODO: modify function `process_etablissements` to focus on the most relevant fields\n",
    "        chunk_etablissements_processed = process_etablissements(\n",
    "            liste_etablissements_sqlite\n",
    "        )\n",
    "        logger += 1\n",
    "        if logger % 1000 == 0:\n",
    "            logging.info(f\"logger={logger}\")\n",
    "        try:\n",
    "            chunk_doc_generator = elasticsearch_doc_generator(\n",
    "                chunk_etablissements_processed\n",
    "            )\n",
    "            # Bulk index documents into elasticsearch using the parallel version of the\n",
    "            # bulk helper that runs in multiple threads\n",
    "            # The bulk helper accept an instance of Elasticsearch class and an\n",
    "            # iterable, a generator in our case\n",
    "            for success, details in parallel_bulk(\n",
    "                elastic_connection, chunk_doc_generator, chunk_size=elastic_bulk_size\n",
    "            ):\n",
    "                if not success:\n",
    "                    raise Exception(f\"A file_access document failed: {details}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to send to Elasticsearch: {e}\")\n",
    "        doc_count = elastic_connection.cat.count(\n",
    "            index=elastic_index, params={\"format\": \"json\"}\n",
    "        )[0][\"count\"]\n",
    "        logging.info(f\"Number of documents indexed: {doc_count}\")\n",
    "    return doc_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d689dc4-4385-4828-a81e-8246f13dbd37",
   "metadata": {},
   "source": [
    "## Summary of pipeline steps\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/main/DAG-insert-elk-sirene.py"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78bacda2-71a8-4ce6-81e8-90d5a2da566d",
   "metadata": {},
   "source": [
    "\n",
    "create_sqlite_database = PythonOperator(\n",
    "    task_id=\"create_sqlite_database\",\n",
    "    provide_context=True,\n",
    "    python_callable=create_sqlite_database,\n",
    ")\n",
    "\n",
    "# count_nombre_etablissements_ouverts\n",
    "\n",
    "create_etablissement_table = PythonOperator(\n",
    "    task_id=\"create_etablissement_table\",\n",
    "    provide_context=True,\n",
    "    python_callable=create_etablissement_table,\n",
    ")\n",
    "\n",
    "\n",
    "create_elastic_index = PythonOperator(\n",
    "    task_id=\"create_elastic_index\",\n",
    "    provide_context=True,\n",
    "    python_callable=create_elastic_index,\n",
    ")\n",
    "\n",
    "fill_elastic_index = PythonOperator(\n",
    "    task_id=\"fill_elastic_index\",\n",
    "    provide_context=True,\n",
    "    python_callable=fill_elastic_index,\n",
    ")\n",
    "\n",
    "check_elastic_index = PythonOperator(\n",
    "    task_id=\"check_elastic_index\",\n",
    "    provide_context=True,\n",
    "    python_callable=check_elastic_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ae058-8376-4a9d-87e0-9941de8c9800",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Launch the processs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb041b-2f5d-4c2a-be94-90d330998ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create_sqlite_database()\n",
    "create_unite_legale_table()\n",
    "create_etablissement_table()\n",
    "count_nombre_etablissements_ouverts()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc82e5b-4d0f-4ee7-afea-7a1b30cd7014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create_elastic_index()\n",
    "fill_elastic_index()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9690736d-ce0f-46ef-81b8-ddc39065db02",
   "metadata": {},
   "source": [
    "## Copy the etablissement table sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dadb04-ab82-408f-b7c2-addd089276b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e14e97-572b-49b9-be87-16281e37993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    conn, siret_db_cursor = connect_to_db()\n",
    "    print(siret_db_cursor.execute(\"SELECT name FROM sqlite_schema WHERE type='table'\").fetchall())\n",
    "    print(siret_db_cursor.execute(\"SELECT  count(*) from unite_legale\").fetchall())\n",
    "    print(siret_db_cursor.execute(\"SELECT  count(*) from siret\").fetchall())\n",
    "    print(siret_db_cursor.execute(\"SELECT  count(*) from count_etab_ouvert\").fetchall())\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dbbb51-fae4-49ea-973e-d3166b9f5e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_nombre_etablissements_ouverts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0268264e-2aff-4dd0-b291-e6ad9b4d0abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
