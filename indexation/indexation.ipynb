{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18ba968-9f71-4577-9c4a-4bed97071180",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fill index _etablissements_ of elasticsearch\n",
    "elastic path : http://elasticsearch-master:9200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "449e748e-2494-43f1-a833-b14adbcddbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch_dsl in /opt/conda/lib/python3.9/site-packages (7.4.0)\n",
      "Requirement already satisfied: elasticsearch<8.0.0,>=7.0.0 in /opt/conda/lib/python3.9/site-packages (from elasticsearch_dsl) (7.17.6)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.9/site-packages (from elasticsearch_dsl) (2.8.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from elasticsearch_dsl) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from elasticsearch<8.0.0,>=7.0.0->elasticsearch_dsl) (1.26.9)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from elasticsearch<8.0.0,>=7.0.0->elasticsearch_dsl) (2022.5.18.1)\n",
      "Requirement already satisfied: minio in /opt/conda/lib/python3.9/site-packages (7.1.11)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.9/site-packages (from minio) (1.26.9)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.9/site-packages (from minio) (2022.5.18.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install elasticsearch_dsl\n",
    "#!pip install minio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87a5e87a-773d-4086-94dd-e964764f3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mc cp s3/projet-matchsiret/sirene.db data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0c944b-5e23-467b-a1c4-d1ef1ccc0570",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### helpers utils \n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/helpers/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f44689b-5048-4932-b457-87369347a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unique_list(lst):\n",
    "    ulist = []\n",
    "    [ulist.append(x) for x in lst if x not in ulist]\n",
    "    return ulist\n",
    "\n",
    "\n",
    "def unique_string(a):\n",
    "    return \" \".join(unique_list(a.strip().split(\",\"))).strip()\n",
    "\n",
    "\n",
    "def get_empty_string_if_none(string):\n",
    "    if string is None:\n",
    "        return \"\"\n",
    "    return string\n",
    "\n",
    "\n",
    "def dict_from_row(row):\n",
    "    return dict(zip(row.keys(), row))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16d80c8-12c5-4633-b5cd-c8242289f3b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### data enrichment\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/data_enrichment.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efcf52a3-d230-4c09-8be9-c7cdf5f8a95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "labels_file_path = \"./data/\"\n",
    "\n",
    "\n",
    "def load_file(file_name: str):\n",
    "    with open(f\"{labels_file_path}{file_name}\") as json_file:\n",
    "        file_decoded = json.load(json_file)\n",
    "    return file_decoded\n",
    "\n",
    "\n",
    "sections_NAF = load_file(\"sections_codes_naf.json\")\n",
    "\n",
    "\n",
    "# Nom complet\n",
    "def format_nom_complet(\n",
    "    nom=None,\n",
    "    nom_usage=None,\n",
    "    nom_raison_sociale=None,\n",
    "    sigle=None,\n",
    "    prenom=None,\n",
    "):\n",
    "    name = None\n",
    "    if prenom or nom or nom_usage:\n",
    "        if nom_usage:\n",
    "            formatted_name = f\" {nom_usage} ({nom})\" if nom else f\" {nom_usage}\"\n",
    "        else:\n",
    "            formatted_name = f\" {nom}\" if nom else \"\"\n",
    "\n",
    "        name = f\"{prenom if prenom else ''}{formatted_name}\"\n",
    "    if nom_raison_sociale:\n",
    "        name = nom_raison_sociale\n",
    "\n",
    "    if sigle:\n",
    "        name = f\"{name} ({sigle})\"\n",
    "    return name.lower().strip() if name else name\n",
    "\n",
    "\n",
    "# Entrepreneur individuel\n",
    "def is_entrepreneur_individuel(nature_juridique_unite_legale):\n",
    "    if nature_juridique_unite_legale in [\"1\", \"10\", \"1000\"]:\n",
    "        return \"true\"\n",
    "    else:\n",
    "        return \"false\"\n",
    "\n",
    "\n",
    "# Section activité principale\n",
    "def label_section_from_activite(activite_principale_unite_legale):\n",
    "    if activite_principale_unite_legale is not None:\n",
    "        code_naf = activite_principale_unite_legale[:2]\n",
    "        section_activite_principale = (\n",
    "            sections_NAF[code_naf] if code_naf in sections_NAF else None\n",
    "        )\n",
    "        return section_activite_principale\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Adresse complète\n",
    "def format_adresse_complete(\n",
    "    complement_adresse,\n",
    "    numero_voie,\n",
    "    indice_repetition,\n",
    "    type_voie,\n",
    "    libelle_voie,\n",
    "    libelle_commune,\n",
    "    libelle_cedex,\n",
    "    distribution_speciale,\n",
    "    commune,\n",
    "    cedex,\n",
    "    libelle_commune_etranger,\n",
    "    libelle_pays_etranger,\n",
    "):\n",
    "    col_list = [\n",
    "        complement_adresse,\n",
    "        numero_voie,\n",
    "        indice_repetition,\n",
    "        type_voie,\n",
    "        libelle_voie,\n",
    "        distribution_speciale,\n",
    "    ]\n",
    "    adresse = \"\"\n",
    "    for column in col_list:\n",
    "        if column:\n",
    "            adresse = adresse + \" \" + column\n",
    "    if cedex is None:\n",
    "        if commune is None:\n",
    "            adresse = adresse\n",
    "        else:\n",
    "            adresse = (\n",
    "                adresse\n",
    "                + \" \"\n",
    "                + get_empty_string_if_none(commune)\n",
    "                + \" \"\n",
    "                + get_empty_string_if_none(libelle_commune)\n",
    "            )\n",
    "    else:\n",
    "        adresse = (\n",
    "            adresse\n",
    "            + \" \"\n",
    "            + get_empty_string_if_none(cedex)\n",
    "            + \" \"\n",
    "            + get_empty_string_if_none(libelle_cedex)\n",
    "        )\n",
    "    etranger_list = [libelle_commune_etranger, libelle_pays_etranger]\n",
    "    for column in etranger_list:\n",
    "        if column:\n",
    "            adresse = adresse + \" \" + column if column != \"\" else \"\"\n",
    "    return adresse.strip()\n",
    "\n",
    "\n",
    "# Département\n",
    "def format_departement(commune):\n",
    "    departement = (\n",
    "        str(commune)[:3]\n",
    "        if str(commune)[:2] == \"97\"\n",
    "        else (None if commune is None else str(commune)[:2])\n",
    "    )\n",
    "    return departement\n",
    "\n",
    "\n",
    "# Coordonnées\n",
    "def format_coordonnees(longitude, latitude):\n",
    "    coordonnees = (\n",
    "        None if (longitude is None) or (latitude is None) else f\"{latitude},{longitude}\"\n",
    "    )\n",
    "    return coordonnees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca65059-cd6f-4e5f-96ce-e856fb3f8eb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create elastic index\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/elasticsearch/create_sirene_index.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53b392ec-7e58-4b64-87e1-6067847be97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "from elasticsearch_dsl import Index, connections\n",
    "\n",
    "\n",
    "class ElasticCreateSiret:\n",
    "    \"\"\"\n",
    "    Create elasticsearch Index\n",
    "    :param elastic_url: endpoint url of elasticsearch\n",
    "    :type elastic_url: str\n",
    "    :param elastic_index: index to create\n",
    "    :type elastic_index: str\n",
    "    :param elastic_index_shards: number of shards for index\n",
    "    :type elastic_index_shards: int\n",
    "    :param elastic_user: user for elasticsearch\n",
    "    :type elastic_user: str\n",
    "    :param elastic_password: password for elasticsearch\n",
    "    :type elastic_password: str\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        elastic_url: Optional[str] = None,\n",
    "        elastic_index: Optional[str] = None,\n",
    "        elastic_user: Optional[str] = None,\n",
    "        elastic_password: Optional[str] = None,\n",
    "        elastic_bulk_size: Optional[int] = 1500,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        self.elastic_url = elastic_url\n",
    "        self.elastic_index = elastic_index\n",
    "        self.elastic_user = elastic_user\n",
    "        self.elastic_password = elastic_password\n",
    "        self.elastic_bulk_size = elastic_bulk_size\n",
    "\n",
    "        # initiate the default connection to elasticsearch\n",
    "        connections.create_connection(\n",
    "            hosts=[self.elastic_url],\n",
    "            http_auth=(self.elastic_user, self.elastic_password),\n",
    "            retry_on_timeout=True,\n",
    "        )\n",
    "\n",
    "        self.elastic_connection = connections.get_connection()\n",
    "        self.elastic_health = self.elastic_connection.cluster.health()\n",
    "        self.elastic_status = self.elastic_health[\"status\"]\n",
    "        self.elastic_mapping = self.elastic_connection.indices.get_mapping()\n",
    "\n",
    "        logging.info(\"Elasticsearch connection initiated!\")\n",
    "\n",
    "    def check_health(self):\n",
    "        if self.elastic_status not in (\"green\", \"yellow\"):\n",
    "            raise Exception(\n",
    "                f\"Cluster status is {self.elastic_status}, not green nor yellow!!\"\n",
    "            )\n",
    "        else:\n",
    "            logging.info(f\"Cluster status is functional: {self.elastic_status}\")\n",
    "\n",
    "    def execute(self):\n",
    "\n",
    "        self.check_health()\n",
    "\n",
    "        if not self.elastic_url:\n",
    "            raise ValueError(\"Please provide elasticsearch url endpoint\")\n",
    "\n",
    "        # if self.elastic_index_shards is not None:\n",
    "        if Index(self.elastic_index).exists():\n",
    "            logging.info(f\"Index  {self.elastic_index} already exists! Deleting...\")\n",
    "            Index(self.elastic_index).delete()\n",
    "            logging.info(f\"Index {self.elastic_index} deleted!\")\n",
    "        logging.info(f\"Creating {self.elastic_index} index!\")\n",
    "        # Create the mapping in elasticsearch\n",
    "        ElasticsearchSireneIndex.init(self.elastic_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35fc78-229b-45cd-910c-2d489b4b1ba8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Process unites legales\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/elasticsearch/process_unites_legales.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b958f678-3e5f-41e5-a5f1-3626e1c308d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_unites_legales(chunk_unites_legales_sqlite):\n",
    "    list_unites_legales_processed = []\n",
    "    for unite_legale in chunk_unites_legales_sqlite:\n",
    "        unite_legale_processed = {}\n",
    "        for field in unite_legale:\n",
    "            if field in [\"enseignes\", \"adresses\"]:\n",
    "                unite_legale_processed[field] = json.loads(unite_legale[field])\n",
    "            else:\n",
    "                unite_legale_processed[field] = unite_legale[field]\n",
    "\n",
    "        # Enseignes\n",
    "        unite_legale_processed[\"liste_enseignes\"] = []\n",
    "        for enseigne in unite_legale_processed[\"enseignes\"]:\n",
    "            unite_legale_processed[\"liste_enseignes\"].extend(\n",
    "                [enseigne[\"enseigne_1\"], enseigne[\"enseigne_2\"], enseigne[\"enseigne_3\"]]\n",
    "            )\n",
    "        unite_legale_processed[\"liste_enseignes\"] = list(\n",
    "            set(filter(None, unite_legale_processed[\"liste_enseignes\"]))\n",
    "        )\n",
    "        del unite_legale_processed[\"enseignes\"]\n",
    "\n",
    "        # Adresses\n",
    "        unite_legale_processed[\"liste_adresses\"] = []\n",
    "        for adresse in unite_legale_processed[\"adresses\"]:\n",
    "            unite_legale_processed[\"liste_adresses\"].append(\n",
    "                format_adresse_complete(\n",
    "                    adresse[\"complement_adresse\"],\n",
    "                    adresse[\"numero_voie\"],\n",
    "                    adresse[\"indice_repetition\"],\n",
    "                    adresse[\"type_voie\"],\n",
    "                    adresse[\"libelle_voie\"],\n",
    "                    adresse[\"libelle_commune\"],\n",
    "                    adresse[\"libelle_cedex\"],\n",
    "                    adresse[\"distribution_speciale\"],\n",
    "                    adresse[\"commune\"],\n",
    "                    adresse[\"cedex\"],\n",
    "                    adresse[\"libelle_commune_etranger\"],\n",
    "                    adresse[\"libelle_pays_etranger\"],\n",
    "                )\n",
    "            )\n",
    "        unite_legale_processed[\"liste_adresses\"] = list(\n",
    "            set(filter(None, unite_legale_processed[\"liste_adresses\"]))\n",
    "        )\n",
    "        del unite_legale_processed[\"adresses\"]\n",
    "\n",
    "        unite_legale_processed[\"adresse_etablissement\"] = format_adresse_complete(\n",
    "            unite_legale_processed[\"complement_adresse\"],\n",
    "            unite_legale_processed[\"numero_voie\"],\n",
    "            unite_legale_processed[\"indice_repetition\"],\n",
    "            unite_legale_processed[\"type_voie\"],\n",
    "            unite_legale_processed[\"libelle_voie\"],\n",
    "            unite_legale_processed[\"libelle_commune\"],\n",
    "            unite_legale_processed[\"libelle_cedex\"],\n",
    "            unite_legale_processed[\"distribution_speciale\"],\n",
    "            unite_legale_processed[\"commune\"],\n",
    "            unite_legale_processed[\"cedex\"],\n",
    "            unite_legale_processed[\"libelle_commune_etranger\"],\n",
    "            unite_legale_processed[\"libelle_pays_etranger\"],\n",
    "        )\n",
    "\n",
    "        unite_legale_processed[\"nom_complet\"] = format_nom_complet(\n",
    "            unite_legale[\"nom\"],\n",
    "            unite_legale[\"nom_usage\"],\n",
    "            unite_legale[\"nom_raison_sociale\"],\n",
    "            unite_legale[\"sigle\"],\n",
    "            unite_legale[\"prenom\"],\n",
    "        )\n",
    "        # Replace missing values with 0\n",
    "        unite_legale_processed[\"nombre_etablissements_ouverts\"] = (\n",
    "            0\n",
    "            if unite_legale_processed[\"nombre_etablissements_ouverts\"] is None\n",
    "            else unite_legale_processed[\"nombre_etablissements_ouverts\"]\n",
    "        )\n",
    "        unite_legale_processed[\n",
    "            \"is_entrepreneur_individuel\"\n",
    "        ] = is_entrepreneur_individuel(unite_legale[\"nature_juridique_unite_legale\"])\n",
    "        unite_legale_processed[\n",
    "            \"section_activite_principale\"\n",
    "        ] = label_section_from_activite(\n",
    "            unite_legale[\"activite_principale_unite_legale\"]\n",
    "        )\n",
    "        unite_legale_processed[\"departement\"] = format_departement(\n",
    "            unite_legale[\"commune\"]\n",
    "        )\n",
    "        unite_legale_processed[\"coordonnees\"] = format_coordonnees(\n",
    "            unite_legale[\"longitude\"], unite_legale[\"latitude\"]\n",
    "        )\n",
    "        unite_legale_processed[\"concat_enseigne_adresse\"] = (\n",
    "            unite_legale_processed[\"liste_enseignes\"]\n",
    "            + unite_legale_processed[\"liste_adresses\"]\n",
    "        )\n",
    "\n",
    "        unite_legale_processed[\"concat_nom_adr_siren\"] = (\n",
    "            get_empty_string_if_none(unite_legale_processed[\"nom_complet\"])\n",
    "            + \" \"\n",
    "            + get_empty_string_if_none(unite_legale_processed[\"adresse_etablissement\"])\n",
    "            + \" \"\n",
    "            + get_empty_string_if_none(unite_legale[\"siren\"])\n",
    "        ).strip()\n",
    "        list_unites_legales_processed.append(unite_legale_processed)\n",
    "    return list_unites_legales_processed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d88fba0-a5ee-4eb5-b3fa-41d27d9ae4c0",
   "metadata": {},
   "source": [
    "### Process etablissements\n",
    "adapted from process unites legales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf90f9ee-2016-46c7-8697-14d61a0219d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "def process_etablissements(chunk_etablissements_sqlite: Tuple):\n",
    "    list_etablissements_processed = []\n",
    "    for etablissement in chunk_etablissements_sqlite:\n",
    "        etablissement_processed = {\"enseignes\": [], \"adresses\":[]}\n",
    "        \n",
    "        for field in etablissement:\n",
    "            if field in [\"enseignes\", \"adresses\"]: # nested fields\n",
    "                etablissement_processed[field] = json.loads(etablissement[field])\n",
    "            else:\n",
    "                etablissement_processed[field] = etablissement[field]\n",
    "\n",
    "        # Enseignes\n",
    "        etablissement_processed[\"liste_enseignes\"] = []\n",
    "        for enseigne in etablissement_processed[\"enseignes\"]:\n",
    "            etablissement_processed[\"liste_enseignes\"].extend(\n",
    "                [enseigne[\"enseigne_1\"], enseigne[\"enseigne_2\"], enseigne[\"enseigne_3\"]]\n",
    "            )\n",
    "        etablissement_processed[\"liste_enseignes\"] = list(\n",
    "            set(filter(None, etablissement_processed[\"liste_enseignes\"]))\n",
    "        )\n",
    "        del etablissement_processed[\"enseignes\"]\n",
    "\n",
    "        # Adresses\n",
    "        etablissement_processed[\"liste_adresses\"] = []\n",
    "        for adresse in etablissement_processed[\"adresses\"]:\n",
    "            etablissement_processed[\"liste_adresses\"].append(\n",
    "                format_adresse_complete(\n",
    "                    adresse[\"complement_adresse\"],\n",
    "                    adresse[\"numero_voie\"],\n",
    "                    adresse[\"indice_repetition\"],\n",
    "                    adresse[\"type_voie\"],\n",
    "                    adresse[\"libelle_voie\"],\n",
    "                    adresse[\"libelle_commune\"],\n",
    "                    adresse[\"libelle_cedex\"],\n",
    "                    adresse[\"distribution_speciale\"],\n",
    "                    adresse[\"commune\"],\n",
    "                    adresse[\"cedex\"],\n",
    "                    adresse[\"libelle_commune_etranger\"],\n",
    "                    adresse[\"libelle_pays_etranger\"],\n",
    "                )\n",
    "            )\n",
    "        etablissement_processed[\"liste_adresses\"] = list(\n",
    "            set(filter(None, etablissement_processed[\"liste_adresses\"]))\n",
    "        )\n",
    "        del etablissement_processed[\"adresses\"]\n",
    "\n",
    "        etablissement_processed[\"adresse_etablissement\"] = format_adresse_complete(\n",
    "            etablissement_processed[\"complement_adresse\"],\n",
    "            etablissement_processed[\"numero_voie\"],\n",
    "            etablissement_processed[\"indice_repetition\"],\n",
    "            etablissement_processed[\"type_voie\"],\n",
    "            etablissement_processed[\"libelle_voie\"],\n",
    "            etablissement_processed[\"libelle_commune\"],\n",
    "            etablissement_processed[\"libelle_cedex\"],\n",
    "            etablissement_processed[\"distribution_speciale\"],\n",
    "            etablissement_processed[\"commune\"],\n",
    "            etablissement_processed[\"cedex\"],\n",
    "            etablissement_processed[\"libelle_commune_etranger\"],\n",
    "            etablissement_processed[\"libelle_pays_etranger\"],\n",
    "        )\n",
    "\n",
    "        etablissement_processed[\"nom_complet\"] = format_nom_complet(\n",
    "            etablissement[\"nom\"],\n",
    "            etablissement[\"nom_usage\"],\n",
    "            etablissement[\"nom_raison_sociale\"],\n",
    "            etablissement[\"sigle\"],\n",
    "            etablissement[\"prenom\"],\n",
    "        )\n",
    "        # Replace missing values with 0\n",
    "        etablissement_processed[\"nombre_etablissements_ouverts\"] = (\n",
    "            0\n",
    "            if etablissement_processed[\"nombre_etablissements_ouverts\"] is None\n",
    "            else etablissement_processed[\"nombre_etablissements_ouverts\"]\n",
    "        )\n",
    "        etablissement_processed[\n",
    "            \"is_entrepreneur_individuel\"\n",
    "        ] = is_entrepreneur_individuel(etablissement[\"nature_juridique_etablissement\"])\n",
    "        etablissement_processed[\n",
    "            \"section_activite_principale\"\n",
    "        ] = label_section_from_activite(\n",
    "            etablissement[\"activite_principale_etablissement\"]\n",
    "        )\n",
    "        etablissement_processed[\"departement\"] = format_departement(\n",
    "            etablissement[\"commune\"]\n",
    "        )\n",
    "        etablissement_processed[\"coordonnees\"] = format_coordonnees(\n",
    "            etablissement[\"longitude\"], etablissement[\"latitude\"]\n",
    "        )\n",
    "        etablissement_processed[\"concat_enseigne_adresse\"] = (\n",
    "            etablissement_processed[\"liste_enseignes\"]\n",
    "            + etablissement_processed[\"liste_adresses\"]\n",
    "        )\n",
    "\n",
    "        etablissement_processed[\"concat_nom_adr_siren\"] = (\n",
    "            get_empty_string_if_none(etablissement_processed[\"nom_complet\"])\n",
    "            + \" \"\n",
    "            + get_empty_string_if_none(etablissement_processed[\"adresse_etablissement\"])\n",
    "            + \" \"\n",
    "            + get_empty_string_if_none(etablissement[\"siren\"])\n",
    "        ).strip()\n",
    "        list_etablissements_processed.append(etablissement_processed)\n",
    "    return list_etablissements_processed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a86ebd-4bd5-48d1-b369-4340b22feb13",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Mapping unites legales\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/elasticsearch/mapping_sirene_index.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8234a77e-9a7b-4781-bc8a-aa06833165da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch_dsl import (\n",
    "    Boolean,\n",
    "    Date,\n",
    "    Document,\n",
    "    GeoPoint,\n",
    "    Integer,\n",
    "    Keyword,\n",
    "    Text,\n",
    "    analyzer,\n",
    "    token_filter,\n",
    "    tokenizer,\n",
    ")\n",
    "\n",
    "# Define filters\n",
    "french_elision = token_filter(\n",
    "    \"french_elision\",\n",
    "    type=\"elision\",\n",
    "    articles_case=True,\n",
    "    articles=[\n",
    "        \"l\",\n",
    "        \"m\",\n",
    "        \"t\",\n",
    "        \"qu\",\n",
    "        \"n\",\n",
    "        \"s\",\n",
    "        \"j\",\n",
    "        \"d\",\n",
    "        \"c\",\n",
    "        \"jusqu\",\n",
    "        \"quoiqu\",\n",
    "        \"lorsqu\",\n",
    "        \"puisqu\",\n",
    "    ],\n",
    ")\n",
    "french_stop = token_filter(\"french_stop\", type=\"stop\", stopwords=\"_french_\")\n",
    "french_stemmer = token_filter(\"french_stemmer\", type=\"stemmer\", language=\"light_french\")\n",
    "# ignore_case option deprecated, use lowercase filter before synonym filter\n",
    "french_synonym = token_filter(\n",
    "    \"french_synonym\", type=\"synonym\", expand=True, synonyms=[]\n",
    ")\n",
    "\n",
    "# Define analyzer\n",
    "annuaire_analyzer = analyzer(\n",
    "    \"annuaire_analyzer\",\n",
    "    tokenizer=tokenizer(\"icu_tokenizer\"),\n",
    "    filter=[\n",
    "        \"lowercase\",\n",
    "        french_elision,\n",
    "        french_stop,\n",
    "        \"icu_folding\",\n",
    "        french_synonym,\n",
    "        \"asciifolding\",\n",
    "        french_stemmer,\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "class ElasticsearchSireneIndex(Document):\n",
    "    \"\"\"\n",
    "\n",
    "    Model-like class for persisting documents in elasticsearch.\n",
    "    It's a wrapper around document to create specific mappings and to add settings in\n",
    "    elasticsearch.\n",
    "\n",
    "    Class used to represent etablissements\n",
    "    \"\"\"\n",
    "\n",
    "    activite_principale_siege = Keyword()  # Add index_prefixes option\n",
    "    activite_principale_unite_legale = Keyword()\n",
    "    activite_principale_registre_metier = Keyword()\n",
    "    adresse_etablissement = Text()\n",
    "    categorie_entreprise = Text()\n",
    "    cedex = Keyword()\n",
    "    code_pays_etranger = Text()\n",
    "    code_postal = Keyword()\n",
    "    commune = Keyword()\n",
    "    complement_adresse = Text()\n",
    "    concat_enseigne_adresse = Text(analyzer=annuaire_analyzer)\n",
    "    concat_nom_adr_siren = Text(\n",
    "        analyzer=annuaire_analyzer, fields={\"keyword\": Keyword()}\n",
    "    )\n",
    "    coordonnees = GeoPoint()\n",
    "    date_creation_siege = Date()\n",
    "    date_creation_unite_legale = Date()\n",
    "    date_debut_activite_siege = Date()\n",
    "    date_mise_a_jour = Date()\n",
    "    departement = Keyword()\n",
    "    distribution_speciale = Text()\n",
    "    economie_sociale_solidaire_unite_legale = Keyword()\n",
    "    enseigne = Text()\n",
    "    etat_administratif_unite_legale = Keyword()\n",
    "    etat_administratif_siege = Keyword()\n",
    "    geo_adresse = Text(analyzer=annuaire_analyzer)\n",
    "    geo_id = Keyword()\n",
    "    identifiant_association_unite_legale = Keyword()\n",
    "    indice_repetition = Text()\n",
    "    is_entrepreneur_individuel = Boolean()\n",
    "    is_siege = Boolean()\n",
    "    latitude = Text()\n",
    "    libelle_cedex = Text()\n",
    "    libelle_commune = Text()\n",
    "    libelle_commune_etranger = Text()\n",
    "    libelle_pays_etranger = Text()\n",
    "    libelle_voie = Text()\n",
    "    liste_adresses = Text(analyzer=annuaire_analyzer)\n",
    "    liste_enseignes = Text(analyzer=annuaire_analyzer)\n",
    "    longitude = Text()\n",
    "    nature_juridique_unite_legale = Integer()\n",
    "    nom = Text()\n",
    "    nom_complet = Text(analyzer=annuaire_analyzer, fields={\"keyword\": Keyword()})\n",
    "    nom_raison_sociale = Text()\n",
    "  #  nombre_etablissements = Integer()  # NaN can't be stored in an integer array\n",
    "  #  nombre_etablissements_ouverts = Integer()\n",
    "    numero_voie = Text()\n",
    "    prenom = Keyword()\n",
    "    section_activite_principale = Keyword()\n",
    "    sigle = Keyword()\n",
    "    siren = Keyword(required=True)\n",
    "    siret_siege = Keyword(required=True)\n",
    "    type_voie = Text()\n",
    "    tranche_effectif_salarie_siege = Keyword()\n",
    "    tranche_effectif_salarie_unite_legale = Keyword()\n",
    "\n",
    "    class Index:\n",
    "        settings = {\"number_of_shards\": 1, \"number_of_replicas\": 0}\n",
    "        name = \"siret\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2be50-69d3-41e0-96c1-a5c779d37aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "541179bd-5ee8-44d8-be79-cb46bda22e6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fill database and index\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/task_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f6e7359-6ca6-488e-853d-ce78319fc837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sqlite3\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from elasticsearch_dsl import connections\n",
    "#from minio import Minio\n",
    "\n",
    "DATA_DIR = \"/home/jovyan/work/matchSIRET/indexation/data/\"\n",
    "DATABASE_LOCATION = DATA_DIR + \"sirene.db\"\n",
    "ELASTIC_BULK_SIZE = 1500\n",
    "\n",
    "ELASTIC_PASSWORD = \"\"\n",
    "ELASTIC_URL = \"http://elasticsearch-master:9200\"\n",
    "ELASTIC_USER = \"\"\n",
    "\n",
    "\n",
    "# Connect to database\n",
    "def connect_to_db():\n",
    "    siret_db_conn = sqlite3.connect(DATABASE_LOCATION)\n",
    "    logging.info(\"******************* Connecting to database! *******************\")\n",
    "    siret_db_cursor = siret_db_conn.cursor()\n",
    "    return siret_db_conn, siret_db_cursor\n",
    "\n",
    "\n",
    "def commit_and_close_conn(siret_db_conn):\n",
    "    siret_db_conn.commit()\n",
    "    siret_db_conn.close()\n",
    "\n",
    "\n",
    "def create_sqlite_database():\n",
    "    if os.path.exists(DATA_DIR) and os.path.isdir(DATA_DIR):\n",
    "        shutil.rmtree(DATA_DIR)\n",
    "    os.makedirs(os.path.dirname(DATA_DIR), exist_ok=True)\n",
    "    if os.path.exists(DATABASE_LOCATION):\n",
    "        os.remove(DATABASE_LOCATION)\n",
    "        logging.info(\n",
    "            \"******************** Existing database removed from {DATABASE_LOCATION}\"\n",
    "        )\n",
    "    siren_db_conn = sqlite3.connect(DATABASE_LOCATION)\n",
    "    logging.info(\n",
    "        \"******************* Creating and connecting to database! *******************\"\n",
    "    )\n",
    "    commit_and_close_conn(siren_db_conn)\n",
    "\n",
    "\n",
    "def create_etablissement_table():\n",
    "    siren_db_conn, siren_db_cursor = connect_to_db()\n",
    "    # Create list of departement zip codes\n",
    "    all_deps = [\n",
    "        *\"-0\".join(list(str(x) for x in range(0, 10))).split(\"-\")[1:],\n",
    "        *list(str(x) for x in range(10, 20)),\n",
    "        *[\"2A\", \"2B\"],\n",
    "        *list(str(x) for x in range(21, 96)),\n",
    "        *\"-7510\".join(list(str(x) for x in range(0, 10))).split(\"-\")[1:],\n",
    "        *\"-751\".join(list(str(x) for x in range(9, 21))).split(\"-\")[1:],\n",
    "        *[\"971\", \"972\", \"973\", \"974\", \"976\", \"98\"],\n",
    "        *[\"\"],\n",
    "    ]\n",
    "    # Remove Paris zip code\n",
    "    all_deps.remove(\"75\")\n",
    "\n",
    "    # Create database\n",
    "    siren_db_cursor.execute(\"\"\"DROP TABLE IF EXISTS siret\"\"\")\n",
    "    siren_db_cursor.execute(\n",
    "        \"\"\"CREATE TABLE IF NOT EXISTS siret\n",
    "            (\n",
    "            id INTEGER NOT NULL PRIMARY KEY,\n",
    "            siren,\n",
    "            siret,\n",
    "            date_creation,\n",
    "            tranche_effectif_salarie,\n",
    "            activite_principale_registre_metier,\n",
    "            is_siege,\n",
    "            numero_voie,\n",
    "            type_voie,\n",
    "            libelle_voie,\n",
    "            code_postal,\n",
    "            libelle_cedex,\n",
    "            libelle_commune,\n",
    "            commune,\n",
    "            complement_adresse,\n",
    "            complement_adresse_2,\n",
    "            numero_voie_2,\n",
    "            indice_repetition_2,\n",
    "            type_voie_2,\n",
    "            libelle_voie_2,\n",
    "            commune_2,\n",
    "            libelle_commune_2,\n",
    "            cedex_2,\n",
    "            libelle_cedex_2,\n",
    "            cedex,\n",
    "            date_debut_activite,\n",
    "            distribution_speciale,\n",
    "            distribution_speciale_2,\n",
    "            etat_administratif_etablissement,\n",
    "            enseigne_1,\n",
    "            enseigne_2,\n",
    "            enseigne_3,\n",
    "            activite_principale,\n",
    "            indice_repetition,\n",
    "            nom_commercial,\n",
    "            libelle_commune_etranger,\n",
    "            code_pays_etranger,\n",
    "            libelle_pays_etranger,\n",
    "            libelle_commune_etranger_2,\n",
    "            code_pays_etranger_2,\n",
    "            libelle_pays_etranger_2,\n",
    "            longitude,\n",
    "            latitude,\n",
    "            geo_adresse,\n",
    "            geo_id)\n",
    "            \"\"\"\n",
    "    )\n",
    "    siren_db_cursor.execute(\n",
    "        \"\"\"\n",
    "        CREATE INDEX index_siret\n",
    "        ON siret (siren);\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Upload geo data by departement\n",
    "    for dep in all_deps:\n",
    "        url = f\"https://files.data.gouv.fr/geo-sirene/last/dep/geo_siret_{dep}.csv.gz\"\n",
    "        print(url)\n",
    "        df_dep = pd.read_csv(\n",
    "            url,\n",
    "            compression=\"gzip\",\n",
    "            dtype=str,\n",
    "            usecols=[\n",
    "                \"siren\",\n",
    "                \"siret\",\n",
    "                \"dateCreationEtablissement\",\n",
    "                \"trancheEffectifsEtablissement\",\n",
    "                \"activitePrincipaleRegistreMetiersEtablissement\",\n",
    "                \"etablissementSiege\",\n",
    "                \"numeroVoieEtablissement\",\n",
    "                \"libelleVoieEtablissement\",\n",
    "                \"codePostalEtablissement\",\n",
    "                \"libelleCommuneEtablissement\",\n",
    "                \"libelleCedexEtablissement\",\n",
    "                \"typeVoieEtablissement\",\n",
    "                \"codeCommuneEtablissement\",\n",
    "                \"codeCedexEtablissement\",\n",
    "                \"complementAdresseEtablissement\",\n",
    "                \"distributionSpecialeEtablissement\",\n",
    "                \"complementAdresse2Etablissement\",\n",
    "                \"indiceRepetition2Etablissement\",\n",
    "                \"libelleCedex2Etablissement\",\n",
    "                \"codeCedex2Etablissement\",\n",
    "                \"numeroVoie2Etablissement\",\n",
    "                \"typeVoie2Etablissement\",\n",
    "                \"libelleVoie2Etablissement\",\n",
    "                \"codeCommune2Etablissement\",\n",
    "                \"libelleCommune2Etablissement\",\n",
    "                \"distributionSpeciale2Etablissement\",\n",
    "                \"dateDebut\",\n",
    "                \"etatAdministratifEtablissement\",\n",
    "                \"enseigne1Etablissement\",\n",
    "                \"enseigne1Etablissement\",\n",
    "                \"enseigne2Etablissement\",\n",
    "                \"enseigne3Etablissement\",\n",
    "                \"denominationUsuelleEtablissement\",\n",
    "                \"activitePrincipaleEtablissement\",\n",
    "                \"geo_adresse\",\n",
    "                \"geo_id\",\n",
    "                \"longitude\",\n",
    "                \"latitude\",\n",
    "                \"indiceRepetitionEtablissement\",\n",
    "                \"libelleCommuneEtrangerEtablissement\",\n",
    "                \"codePaysEtrangerEtablissement\",\n",
    "                \"libellePaysEtrangerEtablissement\",\n",
    "                \"libelleCommuneEtranger2Etablissement\",\n",
    "                \"codePaysEtranger2Etablissement\",\n",
    "                \"libellePaysEtranger2Etablissement\",\n",
    "            ],\n",
    "        )\n",
    "        df_dep = df_dep.rename(\n",
    "            columns={\n",
    "                \"dateCreationEtablissement\": \"date_creation\",\n",
    "                \"trancheEffectifsEtablissement\": \"tranche_effectif_salarie\",\n",
    "                \"activitePrincipaleRegistreMetiersEtablissement\": \"activite_principale\"\n",
    "                \"_registre_metier\",\n",
    "                \"etablissementSiege\": \"is_siege\",\n",
    "                \"numeroVoieEtablissement\": \"numero_voie\",\n",
    "                \"typeVoieEtablissement\": \"type_voie\",\n",
    "                \"libelleVoieEtablissement\": \"libelle_voie\",\n",
    "                \"codePostalEtablissement\": \"code_postal\",\n",
    "                \"libelleCedexEtablissement\": \"libelle_cedex\",\n",
    "                \"libelleCommuneEtablissement\": \"libelle_commune\",\n",
    "                \"codeCommuneEtablissement\": \"commune\",\n",
    "                \"complementAdresseEtablissement\": \"complement_adresse\",\n",
    "                \"complementAdresse2Etablissement\": \"complement_adresse_2\",\n",
    "                \"numeroVoie2Etablissement\": \"numero_voie_2\",\n",
    "                \"indiceRepetition2Etablissement\": \"indice_repetition_2\",\n",
    "                \"typeVoie2Etablissement\": \"type_voie_2\",\n",
    "                \"libelleVoie2Etablissement\": \"libelle_voie_2\",\n",
    "                \"codeCommune2Etablissement\": \"commune_2\",\n",
    "                \"libelleCommune2Etablissement\": \"libelle_commune_2\",\n",
    "                \"codeCedex2Etablissement\": \"cedex_2\",\n",
    "                \"libelleCedex2Etablissement\": \"libelle_cedex_2\",\n",
    "                \"codeCedexEtablissement\": \"cedex\",\n",
    "                \"dateDebut\": \"date_debut_activite\",\n",
    "                \"distributionSpecialeEtablissement\": \"distribution_speciale\",\n",
    "                \"distributionSpeciale2Etablissement\": \"distribution_speciale_2\",\n",
    "                \"etatAdministratifEtablissement\": \"etat_administratif_etablissement\",\n",
    "                \"enseigne1Etablissement\": \"enseigne_1\",\n",
    "                \"enseigne2Etablissement\": \"enseigne_2\",\n",
    "                \"enseigne3Etablissement\": \"enseigne_3\",\n",
    "                \"activitePrincipaleEtablissement\": \"activite_principale\",\n",
    "                \"indiceRepetitionEtablissement\": \"indice_repetition\",\n",
    "                \"denominationUsuelleEtablissement\": \"nom_commercial\",\n",
    "                \"libelleCommuneEtrangerEtablissement\": \"libelle_commune_etranger\",\n",
    "                \"codePaysEtrangerEtablissement\": \"code_pays_etranger\",\n",
    "                \"libellePaysEtrangerEtablissement\": \"libelle_pays_etranger\",\n",
    "                \"libelleCommuneEtranger2Etablissement\": \"libelle_commune_etranger_2\",\n",
    "                \"codePaysEtranger2Etablissement\": \"code_pays_etranger_2\",\n",
    "                \"libellePaysEtranger2Etablissement\": \"libelle_pays_etranger_2\",\n",
    "            }\n",
    "        )\n",
    "        df_dep.to_sql(\"siret\", siren_db_conn, if_exists=\"append\", index=False)\n",
    "        siren_db_conn.commit()\n",
    "        for row in siren_db_cursor.execute(\"\"\"SELECT COUNT() FROM siret\"\"\"):\n",
    "            logging.info(\n",
    "                f\"************ {row} records have been added to the unite_legale table!\"\n",
    "            )\n",
    "    del df_dep\n",
    "    commit_and_close_conn(siren_db_conn)\n",
    "\n",
    "\n",
    "def count_nombre_etablissements():\n",
    "    # Connect to database\n",
    "    siren_db_conn, siren_db_cursor = connect_to_db()\n",
    "    # Create a count table\n",
    "    siren_db_cursor.execute(\"\"\"DROP TABLE IF EXISTS count_etab\"\"\")\n",
    "    siren_db_cursor.execute(\n",
    "        \"\"\"CREATE TABLE count_etab (siren VARCHAR(10), count INTEGER)\"\"\"\n",
    "    )\n",
    "    # Create index\n",
    "    siren_db_cursor.execute(\n",
    "        \"\"\"\n",
    "        CREATE UNIQUE INDEX index_count_siren\n",
    "        ON count_etab (siren);\n",
    "        \"\"\"\n",
    "    )\n",
    "    siren_db_cursor.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO count_etab (siren, count)\n",
    "        SELECT siren, count(*) as count\n",
    "        FROM siret GROUP BY siren;\n",
    "        \"\"\"\n",
    "    )\n",
    "    commit_and_close_conn(siren_db_conn)\n",
    "\n",
    "\n",
    "def count_nombre_etablissements_ouverts():\n",
    "    siren_db_conn, siren_db_cursor = connect_to_db()\n",
    "    siren_db_cursor.execute(\"\"\"DROP TABLE IF EXISTS count_etab_ouvert\"\"\")\n",
    "    siren_db_cursor.execute(\n",
    "        \"\"\"CREATE TABLE count_etab_ouvert (siren VARCHAR(10), count INTEGER)\"\"\"\n",
    "    )\n",
    "    siren_db_cursor.execute(\n",
    "        \"\"\"\n",
    "        CREATE UNIQUE INDEX index_count_ouvert_siren\n",
    "        ON count_etab_ouvert (siren);\n",
    "        \"\"\"\n",
    "    )\n",
    "    siren_db_cursor.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO count_etab_ouvert (siren, count)\n",
    "        SELECT siren, count(*) as count\n",
    "        FROM siret\n",
    "        WHERE etat_administratif_etablissement = 'A' GROUP BY siren;\n",
    "        \"\"\"\n",
    "    )\n",
    "    commit_and_close_conn(siren_db_conn)\n",
    "\n",
    "\n",
    "\n",
    "def create_elastic_index(**kwargs):\n",
    "    elastic_index = \"siret\"\n",
    "    logging.info(f\"******************** Index to create: {elastic_index}\")\n",
    "    create_index = ElasticCreateSiret(\n",
    "        elastic_url=ELASTIC_URL,\n",
    "        elastic_index=elastic_index,\n",
    "        elastic_user=ELASTIC_USER,\n",
    "        elastic_password=ELASTIC_PASSWORD,\n",
    "        elastic_bulk_size=ELASTIC_BULK_SIZE,\n",
    "    )\n",
    "    create_index.execute()\n",
    "\n",
    "\n",
    "def fill_elastic_index(**kwargs):\n",
    "    elastic_index = \"siret\"\n",
    "    siret_db_conn, siret_db_cursor = connect_to_db()\n",
    "    siret_db_cursor.execute(\n",
    "        '''\n",
    "        SELECT\n",
    "        st.siret\n",
    "        st.date_creation as date_creation_siege,\n",
    "        st.tranche_effectif_salarie as tranche_effectif_salarie_siege,\n",
    "        st.date_debut_activite as date_debut_activite_siege,\n",
    "        st.etat_administratif_etablissement as etat_administratif_siege,\n",
    "        st.activite_principale as activite_principale_siege,\n",
    "        st.complement_adresse as complement_adresse,\n",
    "        st.numero_voie as numero_voie,\n",
    "        st.indice_repetition as indice_repetition,\n",
    "        st.type_voie as type_voie,\n",
    "        st.libelle_voie as libelle_voie,\n",
    "        st.distribution_speciale as distribution_speciale,\n",
    "        st.cedex as cedex,\n",
    "        st.libelle_cedex as libelle_cedex,\n",
    "        st.commune as commune,\n",
    "        st.libelle_commune as libelle_commune,\n",
    "        st.code_pays_etranger as code_pays_etranger,\n",
    "        st.libelle_commune_etranger as libelle_commune_etranger,\n",
    "        st.libelle_pays_etranger as libelle_pays_etranger,\n",
    "        st.code_postal as code_postal,\n",
    "        st.geo_id as geo_id,\n",
    "        st.longitude as longitude,\n",
    "        st.latitude as latitude,\n",
    "        st.activite_principale_registre_metier as activite_principale_registre_metier,\n",
    "\n",
    "        (SELECT json_group_array(\n",
    "            json_object(\n",
    "                'enseigne_1', enseigne_1,\n",
    "                'enseigne_2', enseigne_2,\n",
    "                'enseigne_3', enseigne_3)\n",
    "            ) FROM\n",
    "            (SELECT enseigne_1, enseigne_2, enseigne_3 from siret\n",
    "            WHERE siren = st.siren)\n",
    "        ) as enseignes,\n",
    "        (SELECT json_group_array(\n",
    "            json_object(\n",
    "            'complement_adresse', complement_adresse,\n",
    "            'numero_voie', numero_voie,\n",
    "            'indice_repetition', indice_repetition,\n",
    "            'type_voie', type_voie,\n",
    "            'libelle_voie', libelle_voie,\n",
    "            'libelle_commune', libelle_commune,\n",
    "            'libelle_cedex', libelle_cedex,\n",
    "            'distribution_speciale', distribution_speciale,\n",
    "            'commune', commune,\n",
    "            'cedex', cedex,\n",
    "            'libelle_commune_etranger', libelle_commune_etranger,\n",
    "            'libelle_pays_etranger', libelle_pays_etranger)\n",
    "            ) FROM\n",
    "            (SELECT complement_adresse, numero_voie, indice_repetition,\n",
    "            type_voie, libelle_voie, libelle_commune, distribution_speciale,\n",
    "            commune, cedex, libelle_commune_etranger, libelle_pays_etranger\n",
    "            FROM siret\n",
    "            WHERE siren = st.siren)\n",
    "            ) as adresses,\n",
    "\n",
    "            st.is_siege as is_siege\n",
    "        FROM\n",
    "            siret st\n",
    "        '''\n",
    "    )\n",
    "    connections.create_connection(\n",
    "        hosts=[ELASTIC_URL],\n",
    "        http_auth=(ELASTIC_USER, ELASTIC_PASSWORD),\n",
    "        retry_on_timeout=True,\n",
    "    )\n",
    "    elastic_connection = connections.get_connection()\n",
    "\n",
    "    \n",
    "    doc_count = index_etablissements_by_chunk(\n",
    "        cursor=siret_db_cursor,\n",
    "        elastic_connection=elastic_connection,\n",
    "        elastic_bulk_size=ELASTIC_BULK_SIZE,\n",
    "        elastic_index=elastic_index,\n",
    "    )\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa5533-9d87-4b01-91c6-05844ee668d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Indexing chunks of unite legale\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/b6d7f44bffec99a1036cca21eb56804abf8e8b4a/elasticsearch/indexing_unite_legale.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "957e7382-700b-4e7f-b37a-a5934345817f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from elasticsearch.helpers import parallel_bulk\n",
    "\n",
    "\n",
    "def elasticsearch_doc_generator(data):\n",
    "    # Serialize the instance into a dictionary so that it can be saved in elasticsearch.\n",
    "    for index, document in enumerate(data):\n",
    "        yield ElasticsearchSireneIndex(\n",
    "            meta={\"id\": document[\"siret\"]}, **document\n",
    "        ).to_dict(include_meta=True)\n",
    "\n",
    "\n",
    "def index_unites_legales_by_chunk(\n",
    "    cursor, elastic_connection, elastic_bulk_size, elastic_index\n",
    "):\n",
    "    logger = 0\n",
    "    chunk_unites_legales_sqlite = 1\n",
    "    while chunk_unites_legales_sqlite:\n",
    "        chunk_unites_legales_sqlite = cursor.fetchmany(elastic_bulk_size)\n",
    "        unite_legale_columns = tuple([x[0] for x in cursor.description])\n",
    "        liste_unites_legales_sqlite = []\n",
    "        # Group all fetched unites_legales from sqlite in one list\n",
    "        for unite_legale in chunk_unites_legales_sqlite:\n",
    "            liste_unites_legales_sqlite.append(\n",
    "                {\n",
    "                    unite_legale_columns: value\n",
    "                    for unite_legale_columns, value in zip(\n",
    "                        unite_legale_columns, unite_legale\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "        liste_unites_legales_sqlite = tuple(liste_unites_legales_sqlite)\n",
    "\n",
    "        chunk_unites_legales_processed = process_unites_legales(\n",
    "            liste_unites_legales_sqlite\n",
    "        )\n",
    "        logger += 1\n",
    "        if logger % 1000 == 0:\n",
    "            logging.info(f\"logger={logger}\")\n",
    "        try:\n",
    "            chunk_doc_generator = elasticsearch_doc_generator(\n",
    "                chunk_unites_legales_processed\n",
    "            )\n",
    "            # Bulk index documents into elasticsearch using the parallel version of the\n",
    "            # bulk helper that runs in multiple threads\n",
    "            # The bulk helper accept an instance of Elasticsearch class and an\n",
    "            # iterable, a generator in our case\n",
    "            for success, details in parallel_bulk(\n",
    "                elastic_connection, chunk_doc_generator, chunk_size=elastic_bulk_size\n",
    "            ):\n",
    "                if not success:\n",
    "                    raise Exception(f\"A file_access document failed: {details}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to send to Elasticsearch: {e}\")\n",
    "        doc_count = elastic_connection.cat.count(\n",
    "            index=elastic_index, params={\"format\": \"json\"}\n",
    "        )[0][\"count\"]\n",
    "        logging.info(f\"Number of documents indexed: {doc_count}\")\n",
    "    return doc_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce1c7ae-588d-442e-b253-d72ae0d10415",
   "metadata": {},
   "source": [
    "### Indexing chunks of etablissements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "47b1a04c-7d8c-4d5a-95d0-b0c417c9bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_etablissements_by_chunk(\n",
    "    cursor, elastic_connection, elastic_bulk_size, elastic_index\n",
    "):\n",
    "    logger = 0\n",
    "    chunk_etablissements_sqlite = 1\n",
    "    while chunk_etablissements_sqlite:\n",
    "        chunk_etablissements_sqlite = cursor.fetchmany(elastic_bulk_size)\n",
    "        etablissements_columns = tuple([x[0] for x in cursor.description])\n",
    "        liste_etablissements_sqlite = []\n",
    "        # Group all fetched etablissements from sqlite in one list\n",
    "        for etablissement in chunk_etablissements_sqlite:\n",
    "            liste_etablissements_sqlite.append(\n",
    "                {\n",
    "                    etablissement_column: value\n",
    "                    for etablissement_column, value in zip(\n",
    "                        etablissements_columns, etablissement\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "        liste_etablissements_sqlite = tuple(liste_etablissements_sqlite)\n",
    "\n",
    "        # TODO: modify function `process_etablissements` to focus on the most relevant fields\n",
    "        chunk_etablissements_processed = process_etablissements(\n",
    "            liste_etablissements_sqlite\n",
    "        )\n",
    "        logger += 1\n",
    "        if logger % 1000 == 0:\n",
    "            logging.info(f\"logger={logger}\")\n",
    "        try:\n",
    "            chunk_doc_generator = elasticsearch_doc_generator(\n",
    "                chunk_etablissements_processed\n",
    "            )\n",
    "            # Bulk index documents into elasticsearch using the parallel version of the\n",
    "            # bulk helper that runs in multiple threads\n",
    "            # The bulk helper accept an instance of Elasticsearch class and an\n",
    "            # iterable, a generator in our case\n",
    "            for success, details in parallel_bulk(\n",
    "                elastic_connection, chunk_doc_generator, chunk_size=elastic_bulk_size\n",
    "            ):\n",
    "                if not success:\n",
    "                    raise Exception(f\"A file_access document failed: {details}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to send to Elasticsearch: {e}\")\n",
    "        doc_count = elastic_connection.cat.count(\n",
    "            index=elastic_index, params={\"format\": \"json\"}\n",
    "        )[0][\"count\"]\n",
    "        logging.info(f\"Number of documents indexed: {doc_count}\")\n",
    "    return doc_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d689dc4-4385-4828-a81e-8246f13dbd37",
   "metadata": {},
   "source": [
    "## Summary of pipeline steps\n",
    "https://github.com/etalab/annuaire-entreprises-search-infra/blob/main/DAG-insert-elk-sirene.py"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78bacda2-71a8-4ce6-81e8-90d5a2da566d",
   "metadata": {},
   "source": [
    "\n",
    "create_sqlite_database = PythonOperator(\n",
    "    task_id=\"create_sqlite_database\",\n",
    "    provide_context=True,\n",
    "    python_callable=create_sqlite_database,\n",
    ")\n",
    "\n",
    "create_etablissement_table = PythonOperator(\n",
    "    task_id=\"create_etablissement_table\",\n",
    "    provide_context=True,\n",
    "    python_callable=create_etablissement_table,\n",
    ")\n",
    "\n",
    "\n",
    "create_elastic_index = PythonOperator(\n",
    "    task_id=\"create_elastic_index\",\n",
    "    provide_context=True,\n",
    "    python_callable=create_elastic_index,\n",
    ")\n",
    "\n",
    "fill_elastic_index = PythonOperator(\n",
    "    task_id=\"fill_elastic_index\",\n",
    "    provide_context=True,\n",
    "    python_callable=fill_elastic_index,\n",
    ")\n",
    "\n",
    "check_elastic_index = PythonOperator(\n",
    "    task_id=\"check_elastic_index\",\n",
    "    provide_context=True,\n",
    "    python_callable=check_elastic_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ae058-8376-4a9d-87e0-9941de8c9800",
   "metadata": {},
   "source": [
    "# Launch the processs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbc82e5b-4d0f-4ee7-afea-7a1b30cd7014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'nom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfill_elastic_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36mfill_elastic_index\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m connections\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[1;32m    369\u001b[0m     hosts\u001b[38;5;241m=\u001b[39m[ELASTIC_URL],\n\u001b[1;32m    370\u001b[0m     http_auth\u001b[38;5;241m=\u001b[39m(ELASTIC_USER, ELASTIC_PASSWORD),\n\u001b[1;32m    371\u001b[0m     retry_on_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    372\u001b[0m )\n\u001b[1;32m    373\u001b[0m elastic_connection \u001b[38;5;241m=\u001b[39m connections\u001b[38;5;241m.\u001b[39mget_connection()\n\u001b[0;32m--> 375\u001b[0m doc_count \u001b[38;5;241m=\u001b[39m \u001b[43mindex_unites_legales_by_chunk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcursor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msiren_db_cursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43melastic_connection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melastic_connection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43melastic_bulk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mELASTIC_BULK_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43melastic_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melastic_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36mindex_unites_legales_by_chunk\u001b[0;34m(cursor, elastic_connection, elastic_bulk_size, elastic_index)\u001b[0m\n\u001b[1;32m     24\u001b[0m     liste_unites_legales_sqlite\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     25\u001b[0m         {\n\u001b[1;32m     26\u001b[0m             unite_legale_columns: value\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m         }\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     33\u001b[0m liste_unites_legales_sqlite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(liste_unites_legales_sqlite)\n\u001b[0;32m---> 35\u001b[0m chunk_unites_legales_processed \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_unites_legales\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mliste_unites_legales_sqlite\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m logger \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mprocess_unites_legales\u001b[0;34m(chunk_unites_legales_sqlite)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m unite_legale_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madresses\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     46\u001b[0m unite_legale_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madresse_etablissement\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m format_adresse_complete(\n\u001b[1;32m     47\u001b[0m     unite_legale_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplement_adresse\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     48\u001b[0m     unite_legale_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumero_voie\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     unite_legale_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibelle_pays_etranger\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     61\u001b[0m unite_legale_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnom_complet\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m format_nom_complet(\n\u001b[0;32m---> 62\u001b[0m     \u001b[43munite_legale\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     63\u001b[0m     unite_legale[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnom_usage\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     64\u001b[0m     unite_legale[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnom_raison_sociale\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     65\u001b[0m     unite_legale[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigle\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     66\u001b[0m     unite_legale[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprenom\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     67\u001b[0m )\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Replace missing values with 0\u001b[39;00m\n\u001b[1;32m     69\u001b[0m unite_legale_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnombre_etablissements_ouverts\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unite_legale_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnombre_etablissements_ouverts\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m unite_legale_processed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnombre_etablissements_ouverts\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     73\u001b[0m )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'nom'"
     ]
    }
   ],
   "source": [
    "fill_elastic_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9690736d-ce0f-46ef-81b8-ddc39065db02",
   "metadata": {},
   "source": [
    "## Copy the etablissement table sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507967c6-8898-4945-9fc6-82dd6569f76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e14e97-572b-49b9-be87-16281e37993f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dbbb51-fae4-49ea-973e-d3166b9f5e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
